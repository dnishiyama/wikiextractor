{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T23:18:59.848455Z",
     "start_time": "2020-07-24T23:18:41.225Z"
    }
   },
   "source": [
    "Must be on the \"parse_parts\" branch of wikiextractor repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining tasks:\n",
    "* (DONE) Find out why 'afraidness' wasn't captured\n",
    "* Why is karaff a root in https://api.etymologyexplorer.com/dev/get_trees?ids[]=23683&compression=0\n",
    "* make it so that existing entry_connections are used, not overwritten, only overwrite etymologies\n",
    "* (DONE) Then add it so pronunciations and definitions are updated as well (grab this from the spiders?)\n",
    "* fix issue with identifying words that were hyphenated\n",
    "* (DONE) Add connections for definitions (should be able to lift this)\n",
    "* Improve the regexes to provide more accuracy\n",
    "* Make the deep learning model to catch wrong branch choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T15:53:49.495976Z",
     "start_time": "2020-09-23T15:53:47.161003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/04/20 dgnutils update loaded!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dgnutils import *\n",
    "sys.path.append(\"/Users/nish/development/git/etymology_explorer/modules\")\n",
    "from ety_utils import *\n",
    "session=requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T15:53:53.282698Z",
     "start_time": "2020-09-23T15:53:53.147981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'etymologies': '707.61 MB',\n",
       " 'entry_connections': '676.97 MB',\n",
       " 'entry_definitions': '664.67 MB',\n",
       " 'entry_pos': '442.06 MB',\n",
       " 'connection_sources': '269.44 MB',\n",
       " 'entry_etymologies': '218.72 MB',\n",
       " 'connections': '156.80 MB',\n",
       " 'entry_pronunciations': '145.22 MB',\n",
       " 'languages': '3.00 MB',\n",
       " 'permanent_errors': '0.03 MB',\n",
       " 'common_words': '0.03 MB',\n",
       " 'wiktionary_page_dne': '0.02 MB',\n",
       " 'transliterations': '0.02 MB',\n",
       " 'random_etymologies': '0.02 MB',\n",
       " 'progeny': '0.02 MB',\n",
       " 'merged_etymologies': '0.02 MB',\n",
       " 'ancestors': '0.02 MB',\n",
       " 'kin': '0.02 MB'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = os.environ['RDS_ETY_USER']; p = os.environ['RDS_ETY_PASSWORD']; h = os.environ['RDS_ETY_HOST']\n",
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)\n",
    "train_conn, train_cursor = connect('training_data', user=u, password=p, host=h)\n",
    "# test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "# stage_conn, stage_cursor = connect('etymology_explorer_staging', user=u, password=p, host=h)\n",
    "# temp_conn, temp_cursor = connect('temp', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Full Process (1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test xml\n",
    "# head -176534 enwiktionary-latest-pages-articles.xml > test.xml\n",
    "# echo \"</mediawiki>\" >> test.xml\n",
    "# wc -l test.xml\n",
    "# tail -100 test.xml\n",
    "# ./WikiExtractor.py --processes 4 -o output_test --json --no_templates --lists --sections input/test.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T19:16:19.383000Z",
     "start_time": "2020-08-11T19:16:19.156081Z"
    }
   },
   "outputs": [],
   "source": [
    "log_level('d')\n",
    "wp = WikiProcessor(\n",
    "    '/Users/nish/development/git/wikiextractor/', \n",
    "    channel='dev', \n",
    "    store_intermediates=True,\n",
    ")\n",
    "# wp = WikiProcessor('/Users/nish/development/git/wikiextractor/', channel='dev', store_intermediates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:33:25.860665Z",
     "start_time": "2020-08-09T21:14:12.186549Z"
    }
   },
   "outputs": [],
   "source": [
    "# test - 21s\n",
    "# dev - 1 hr 45 min\n",
    "wp.process_wikidump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T22:33:29.191458Z",
     "start_time": "2020-08-09T22:33:25.897144Z"
    }
   },
   "outputs": [],
   "source": [
    "notify('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T21:08:01.452719Z",
     "start_time": "2020-08-09T21:08:01.404135Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "# test_cursor.e('SELECT * FROM entry_etymologies')\n",
    "# test_cursor.e('SHOW TABLES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix dict_insert to allow batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T19:13:06.445894Z",
     "start_time": "2020-08-04T19:12:19.345437Z"
    }
   },
   "outputs": [],
   "source": [
    "database_sizes(wp.cursor) #47s for dev\n",
    "# test = {'connection_sources': 3860, 'connections': 3344, 'entry_connections': 4008, 'entry_definitions': 7250,\n",
    "#  'entry_etymologies': 2469, 'entry_pos': 4011, 'entry_pronunciations': 1999, 'etymologies': 5535,'languages': 13154}\n",
    "\n",
    "# dev = {'connection_sources': 2174854,'connections': 2056605,'entry_connections': 7061624,\n",
    "#  'entry_definitions': 9053405, 'entry_etymologies': 1447349, 'entry_pos': 6689190, 'entry_pronunciations': 1410408,\n",
    "#  'etymologies': 7343477,'languages': 13154}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:16:11.336236Z",
     "start_time": "2020-08-04T14:16:10.897411Z"
    }
   },
   "outputs": [],
   "source": [
    "for w in wp.node_connections:\n",
    "    print(f\"{w[0]['language']:20} {w[0]['word']:20} {w[1]['word']:20} {w[1]['language']:20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Secondary Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T21:04:24.428539Z",
     "start_time": "2020-08-07T20:31:43.252893Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "create_transliteration_table(dev_conn, drop_table=False, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Related words or descendant words\n",
    "# for some words I want to see the related words\n",
    "    # which words?\n",
    "# For some words I want to see the descendant words\n",
    "    # which words? if they have interesting data. Does it depend on the position in tree? Could depend on the\n",
    "    # number of descendants and the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add definitions to etymologies table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:07:47.905523Z",
     "start_time": "2020-08-04T14:07:47.842080Z"
    },
    "collapsed": true
   },
   "source": [
    "#### Individual Functions (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:07:42.125562Z",
     "start_time": "2020-08-04T14:07:42.095977Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(wp.unmatched_words)\n",
    "# wp.unmatched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:10:37.242069Z",
     "start_time": "2020-08-04T14:10:37.115827Z"
    }
   },
   "outputs": [],
   "source": [
    "wp.node_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T04:08:25.038814Z",
     "start_time": "2020-08-02T04:08:24.911469Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ety = wp.cursor.e('SELECT * FROM etymologies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T04:08:27.757215Z",
     "start_time": "2020-08-02T04:08:27.655145Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T02:05:08.650101Z",
     "start_time": "2020-08-02T02:05:08.517806Z"
    }
   },
   "outputs": [],
   "source": [
    "test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "conn = test_conn\n",
    "output_dir = '/Users/nish/development/git/wikiextractor/output/'\n",
    "cache_dir = '/Users/nish/development/git/wikiextractor/input/' # None for trio calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T02:04:33.100589Z",
     "start_time": "2020-08-02T02:04:17.383918Z"
    }
   },
   "outputs": [],
   "source": [
    "test = True\n",
    "log_level('d')\n",
    "with conn.cursor() as cursor:\n",
    "    refresh_tables(cursor, ['etymologies', 'languages'], test=True)      \n",
    "    if test:\n",
    "        logging.debug(f'Inserting etymologies and languages data due to TEST')\n",
    "        cursor.e('INSERT INTO etymologies SELECT * FROM etymology_explorer_prod.etymologies LIMIT 100')\n",
    "        cursor.e('INSERT INTO languages SELECT * FROM etymology_explorer_prod.languages')\n",
    "    wl_2_id, next_wl_2_id = make_wl_2_id_values(cursor)\n",
    "    processed_wikidump = load_wikidump_etymologies(output_dir, test=True);\n",
    "    new_word_lang_pairs, wl_2_id, next_wl_2_id = insert_new_word_lang_pairs(cursor, wl_2_id, next_wl_2_id, processed_wikidump)\n",
    "    ec_dict, ee_dict, en_dict = create_and_insert_mysql_data(cursor, processed_wikidump, wl_2_id, cache_dir) # no cache\n",
    "    \n",
    "    language_dict = create_language_dict(cursor); language_dict['qfa-adm-pro']\n",
    "    wikitext_part_array = get_wikitext_part_array(new_word_lang_pairs, wl_2_id, ec_dict, ee_dict)\n",
    "    all_connections, missed_etymologies = get_connections_from_wikitext_parts(wikitext_part_array)\n",
    "    node_connections = get_nodes_from_connections(all_connections, language_dict)\n",
    "    roots, descs, table_sources, entry_numbers, unmatched_words = get_mysql_data_from_nodes(cursor, node_connections, en_dict, wl_2_id, next_wl_2_id)\n",
    "    insert_unmatched_words_into_mysql(cursor, unmatched_words)\n",
    "    insert_connections_into_mysql(cursor, roots, descs, table_sources, entry_numbers)\n",
    "conn.commit()\n",
    "print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T02:06:56.905330Z",
     "start_time": "2020-08-02T02:06:43.523030Z"
    }
   },
   "outputs": [],
   "source": [
    "# End-to-end Testing: I want to run the entire process with a reduce set of entries, and then it would be easy to change that to include entries that have trouble\n",
    "# Then I know I wont waste time running the entire processes\n",
    "# Setup\n",
    "# test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "conn = test_conn\n",
    "test = True\n",
    "del_after = False\n",
    "output_dir = '/Users/nish/development/git/wikiextractor/output/'\n",
    "cache_dir = '/Users/nish/development/git/wikiextractor/input/'\n",
    "log_level('i')\n",
    "with conn.cursor() as cursor:\n",
    "    \n",
    "    refresh_tables(cursor, exclude=['etymologies', 'languages'], test=True)      \n",
    "    if test:\n",
    "        logging.debug(f'Inserting etymologies and languages data due to TEST')\n",
    "        cursor.e('INSERT INTO etymologies SELECT * FROM etymology_explorer_prod.etymologies LIMIT 100')\n",
    "        cursor.e('INSERT INTO languages SELECT * FROM etymology_explorer_prod.languages')\n",
    "\n",
    "    # IGNORE this step since it can be run and left in place\n",
    "    # ./WikiExtractor.py --processes 4 -o output --json --no_templates --lists --sections input/enwiktionary-latest-pages-articles.xml\n",
    "    \n",
    "#     logging.debug('Creating wl_2_id dictionary...')\n",
    "#     wl_2_id = {(e['word'], e['language_name']):e['_id'] for e in cursor.d('SELECT * FROM etymologies') }\n",
    "    wl_2_id, next_wl_2_id = make_wl_2_id_values(cursor)\n",
    "\n",
    "\n",
    "    # Then take the dump files and make the entry_etymologies (with wikitext) and new words\n",
    "    processed_wikidump = load_wikidump_etymologies(output_dir, test=True);\n",
    "    \n",
    "#     logging.info(f'Found {len(processed_wikidump)} words from the wikiextractor output')\n",
    "\n",
    "    new_word_lang_pairs, _, _ = insert_new_word_lang_pairs(cursor, wl_2_id, next_wl_2_id, processed_wikidump)\n",
    "\n",
    "    # Then take the entry_etymologies and process the wikitext so they are clean\n",
    "    ec_dict, ee_dict, en_dict = create_and_insert_mysql_data(test_cursor, processed_wikidump, wl_2_id, cache_dir)\n",
    "\n",
    "    # Then make the connections based on the wikitext etymologies\n",
    "    logging.info(f'Gathering data for connections...')\n",
    "    \n",
    "    data = [{\n",
    "        '_id':wl_2_id[wl],\n",
    "        'entry_id': ec_dict[wl_2_id[wl]],\n",
    "        'word':wl[0],\n",
    "        'language_name':wl[1],\n",
    "        'wikitext':ee_dict.get(ec_dict[wl_2_id[wl]], None)\n",
    "    } for wl in new_word_lang_pairs]\n",
    "    if del_after: \n",
    "        del ec_dict\n",
    "        del en_dict\n",
    "        del ee_dict\n",
    "    logging.debug(f'Got {len(list(d for d in data if d[\"wikitext\"]))} with wikitext and {len(list(d for d in data if not d[\"wikitext\"]))} without wikitext')\n",
    "    \n",
    "    logging.info(f'Gathering wikitext parts for connections...')\n",
    "    wikitext_part_array = [get_wikitext_parts_dict(entry) for entry in data if entry['wikitext']]\n",
    "    if del_after: del data\n",
    "    \n",
    "    missed_etymologies = []\n",
    "    all_connections = []\n",
    "    for i, wikitext_parts in enumerate(wikitext_part_array):\n",
    "#         if i % 20000 == 0: print(f'\\r{i}/{len(wikitext_part_array)}', end='')\n",
    "        connections, missed_parts = get_entry_connections(wikitext_parts)\n",
    "\n",
    "        if missed_parts:\n",
    "            missed_etymologies.append(missed_parts)\n",
    "        if connections:\n",
    "            all_connections += connections\n",
    "    if del_after: del wikitext_part_array\n",
    "\n",
    "    logging.debug(f'Gathered {len(all_connections)} connections...')\n",
    "    \n",
    "    language_dict = create_language_dict(cursor); language_dict['qfa-adm-pro']\n",
    "    \n",
    "    logging.info(f'Converting connections into nodes...')\n",
    "    nodeConnections = []\n",
    "    for i, connection in enumerate(all_connections):\n",
    "#         if i % 50000 == 0: print(f'\\r{i}/{len(all_connections)}', end='')\n",
    "        nodeConnections += getNodeConnections(connection, language_dict)\n",
    "#     nodeConnections[2003]\n",
    "    if del_after: del all_connections\n",
    "    \n",
    "    logging.info(f'Converting nodes into mysql friendly data and adding missed words...')\n",
    "    unmatched_words = []\n",
    "    next_wl_2_id = max(wl_2_id.values())+1\n",
    "    \n",
    "    # Define local function\n",
    "    def getOrCreateIdWithDict(word, lang, cursor):\n",
    "        global next_wl_2_id, unmatched_words\n",
    "        word = clean_word(word) # removes asterisk and other issues\n",
    "        try:\n",
    "            _id = wl_2_id[(word, lang)]\n",
    "        except KeyError:\n",
    "            word = remove_diacritics(word)\n",
    "            try:\n",
    "                _id = wl_2_id[(word, lang)]\n",
    "            except KeyError:\n",
    "                _id = next_wl_2_id\n",
    "                wl_2_id[(word, lang)] = next_wl_2_id\n",
    "                next_wl_2_id += 1\n",
    "                unmatched_words += [[_id, word, lang]]\n",
    "        return _id\n",
    "    \n",
    "    roots = []; descs = []; table_sources = []; entry_numbers = [];\n",
    "    for i, (desc, root, entry_id) in enumerate(nodeConnections):\n",
    "        desc_id = getOrCreateIdWithDict(desc['word'], desc['language'], cursor)\n",
    "        root_id = getOrCreateIdWithDict(root['word'], root['language'], cursor)\n",
    "\n",
    "        roots.append(root_id)\n",
    "        descs.append(desc_id)\n",
    "        table_sources.append(entry_id)\n",
    "        entry_numbers.append(en_dict[entry_id])\n",
    "    if del_after:\n",
    "        del en_dict\n",
    "        del nodeConnections\n",
    "    \n",
    "    logging.info(f'Found {len(unmatched_words)} unmatched words. Inserting...')\n",
    "    _ids,words,langs = zip(*unmatched_words)\n",
    "    value_dict = {'_id':_ids, 'word':words,'language_name':langs}\n",
    "    insert(\n",
    "        cursor, \n",
    "        'etymologies', \n",
    "        many=True,\n",
    "        **value_dict\n",
    "    )\n",
    "\n",
    "    # Then put those connections in the database\n",
    "    \n",
    "    logging.info(f'Found {len(roots)} connection_sources. Inserting...')\n",
    "    # Connection sources 1.5min\n",
    "    insert(cursor, 'connection_sources', many=True, \n",
    "        **{'root':roots,'descendant':descs,'table_source':table_sources,'entry_number':entry_numbers})\n",
    "\n",
    "    # Connection data 1 min\n",
    "    # make a set for roots, desc\n",
    "    conn_set = set(zip(roots,descs))\n",
    "    roots_set = [s[0] for s in conn_set]\n",
    "    descs_set = [s[1] for s in conn_set]\n",
    "    logging.info(f'Found {len(roots_set)} connection_sources. Inserting...')\n",
    "    insert(cursor,'connections',ignore=True,many=True, **{'root':roots_set,'descendant':descs_set,})\n",
    "    \n",
    "conn.commit()\n",
    "    # Add extra connections based on definitions and such\n",
    "\n",
    "    # Then remove any messed up items (try to move these actions upstream)\n",
    "\n",
    "    # make secondary databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T02:04:52.725772Z",
     "start_time": "2020-08-02T02:04:52.375337Z"
    }
   },
   "outputs": [],
   "source": [
    "database_sizes(test_cursor)\n",
    "# connection_sources 3227\n",
    "# connections 2878\n",
    "# entry_connections 4008\n",
    "# entry_definitions 7250\n",
    "# entry_etymologies 2469\n",
    "# entry_pos 4011\n",
    "# entry_pronunciations 1999\n",
    "# etymologies 5345\n",
    "# languages 13154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T07:45:36.010773Z",
     "start_time": "2020-08-01T07:45:35.986153Z"
    }
   },
   "outputs": [],
   "source": [
    "# nodeConnections[0]\n",
    "# roots[:5]\n",
    "# getOrCreateIdWithDict('man', 'Old Frisian', test_cursor)\n",
    "# dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)\n",
    "# test_conn, test_cursor = connect('etymology_explorer_test', user=u, password=p, host=h)\n",
    "# create_language_dict(test_cursor)['ofs']\n",
    "# prod_conn, prod_cursor = connect('etymology_explorer_prod', user=u, password=p, host=h)\n",
    "# language_dict = create_language_dict(dev_cursor); language_dict['qfa-adm-pro'], language_dict['ofs']\n",
    "# language_dict = create_language_dict(test_cursor); language_dict['qfa-adm-pro'], language_dict['ofs']\n",
    "# language_dict = create_language_dict(prod_cursor); language_dict['qfa-adm-pro'], language_dict['ofs']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T04:52:18.039201Z",
     "start_time": "2020-06-27T04:52:18.035755Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### 1. Wiktionary Dump => Mysql (entry_etymologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:09:53.003449Z",
     "start_time": "2020-07-29T17:09:52.843320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Wiktionary Dump => etymologies (dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T18:26:12.205904Z",
     "start_time": "2020-07-24T18:26:12.183920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run this to get the dump processed\n",
    "# ./WikiExtractor.py --processes 4 -o output --json --no_templates --lists --sections input/enwiktionary-latest-pages-articles.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:17:51.408580Z",
     "start_time": "2020-08-01T05:17:51.182797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_dir = '/Users/nish/development/git/wikiextractor/output/'\n",
    "# etymologies = loadWikidumpEtymologies(output_dir)\n",
    "test_etymologies = loadWikidumpEtymologies(output_dir, test=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:50:54.122955Z",
     "start_time": "2020-07-29T14:50:47.456700Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len([v_i['etymology'] for l in etymologies.values() for v in l.values() for v_i in v if 'etymology' in v_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add the new word-language pairs into etymologies table (use sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:02:21.041279Z",
     "start_time": "2020-07-23T23:01:21.565767Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "current_etymologies = set(dev_cursor.e('SELECT word,language_name FROM etymologies')); len(current_etymologies) #2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:35:00.799912Z",
     "start_time": "2020-08-01T05:35:00.772091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_etymologies = [(word, lang) for word,word_v in test_etymologies.items() for lang in word_v.keys()]\n",
    "len(new_etymologies), new_etymologies[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:20:54.273322Z",
     "start_time": "2020-07-29T17:20:54.046484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_id = dev_cursor.e('SELECT MAX(_id) FROM etymologies')[0][0]; max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:08:59.054761Z",
     "start_time": "2020-07-23T23:04:38.320514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_new_etymologies = new_etymologies - current_etymologies; len(new_new_etymologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:09:21.991875Z",
     "start_time": "2020-07-23T23:08:59.089384Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del new_etymologies\n",
    "del current_etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:10:51.624656Z",
     "start_time": "2020-07-23T23:10:50.688386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "values = []\n",
    "for i,n in enumerate(new_new_etymologies):\n",
    "    if not i % 50000: print(f'\\r{i}/{len(new_new_etymologies)}', end='')\n",
    "    values.append({'_id': i+max_id+1, 'word':n[0], 'language_name':n[1], 'common_descendant':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:11:02.319954Z",
     "start_time": "2020-07-23T23:10:54.934024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 9minutes\n",
    "dev_cursor.dict_insert(values, 'etymologies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T23:11:13.285885Z",
     "start_time": "2020-07-23T23:11:13.178129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Gather table values from etymologies dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create the entry_connections and entry_etymologies tables based on the word-languages and etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:22:51.531419Z",
     "start_time": "2020-07-29T17:20:59.856615Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wl_2_id = {(e['word'], e['language_name']):e['_id'] for e in dev_cursor.d('SELECT * FROM etymologies') }\n",
    "last_id = max(wl_2_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:02:10.613688Z",
     "start_time": "2020-07-29T16:00:56.679820Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get a short sample\n",
    "{k:etymologies[k] for k in list(etymologies)[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:52:00.388302Z",
     "start_time": "2020-08-01T05:52:00.351016Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = create_mysql_data_from_processed_wikiextraction_data(test_etymologies, wl_2_id, log=False)\n",
    "entry_connections_dict_list, \\\n",
    "entry_etymologies_dict_list, \\\n",
    "entry_pos_dict_list, \\\n",
    "entry_pronunciations_dict_list, \\\n",
    "entry_definitions_dict_list, \\\n",
    "etymologies_dict_list = temp\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T05:52:36.045075Z",
     "start_time": "2020-08-01T05:52:36.019214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[len(w) for w in entry_connections_dict_list.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remove wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:29:32.660614Z",
     "start_time": "2020-07-29T17:29:32.611643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:29:35.411774Z",
     "start_time": "2020-07-29T17:29:35.383039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cache_dir = '/Users/nish/development/git/wikiextractor/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:01:31.214014Z",
     "start_time": "2020-07-24T20:00:26.771202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_pronunciations_dict_list['pronunciation'] = multiParseWikitextSentences(\n",
    "    entry_pronunciations_dict_list['pronunciation'], \n",
    "    cache_file=cache_dir+'pron.wik'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:36:13.336740Z",
     "start_time": "2020-07-29T17:35:21.957111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_etymologies_dict_list['etymology'] = multiParseWikitextSentences(\n",
    "    entry_etymologies_dict_list['wikitext'],\n",
    "    cache_file=cache_dir+'ety.wik'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-24T23:26:35.565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_definitions_dict_list['definition'] = multiParseWikitextSentences(\n",
    "    entry_definitions_dict_list['definition'],\n",
    "    cache_file = cache_dir + 'def.wik'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T02:25:08.312024Z",
     "start_time": "2020-07-24T02:24:52.297819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List of templates used in pronunciations\n",
    "set((splitParts(e[e_i[0]+2:e_i[1]-2])[0], len(splitParts(e[e_i[0]+2:e_i[1]-2]))) for e in entry_pronunciations_dict_list['pronunciation'] for e_i in findMatchingBraces(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T19:54:56.543581Z",
     "start_time": "2020-07-24T19:54:56.317719Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[[len(v) for v in e.values()] for e in [entry_connections_dict_list, entry_etymologies_dict_list, entry_pos_dict_list, entry_pronunciations_dict_list, entry_definitions_dict_list, etymologies_dict_list]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MAKE THE normal text from wiki text here for entry_etymologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Insert the table values into mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T23:58:04.193369Z",
     "start_time": "2020-07-24T23:55:54.653246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "defs = dev_cursor.d('SELECT * FROM entry_definitions'); len(defs), defs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T23:58:20.769722Z",
     "start_time": "2020-07-24T23:58:20.677306Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[d['definition'] for d in defs[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T00:07:57.262Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cache_dir = '/Users/nish/development/git/wikiextractor/input/'\n",
    "fixed_defs = multiParseWikitextSentences(\n",
    "    [d['definition'] for d in defs],\n",
    "    cache_file = cache_dir + 'def.wik'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multiParseWikitextSentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:39:00.176330Z",
     "start_time": "2020-07-29T17:39:00.147932Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i=100000\n",
    "entry_etymologies_dict_list['etymology'][i:i+100]\n",
    "# entry_etymologies_dict_list['entry_id'][i:i+100]\n",
    "entry_etymologies_dict_list['wikitext'][i:i+100]\n",
    "# entry_etymologies_dict_list['entry_id'][i:i+100]\n",
    "# entry_connections_dict_list['etymology_id'][100002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T14:32:02.627696Z",
     "start_time": "2020-07-17T14:32:02.504734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(entry_connections_dict_list['etymology_id']), len(entry_connections_dict_list['entry_id']), len(entry_connections_dict_list['entry_number']), len(entry_etymologies_dict_list['entry_id']), len(entry_etymologies_dict_list['etymology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:05:25.263275Z",
     "start_time": "2020-07-24T20:05:25.222948Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_cursor.e('SHOW CREATE TABLE etymologies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:37:00.285195Z",
     "start_time": "2020-07-29T17:36:59.893986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev_cursor.d('SELECT * FROM entry_connections LIMIT 5')\n",
    "# dev_cursor.d('SELECT COuNT(*) FROM entry_etymologies LIMIT 5')\n",
    "# dev_cursor.d('DESCRIBE entry_etymologies')\n",
    "# dev_cursor.d('DELETE FROM entry_connections'); print('done')\n",
    "# dev_cursor.d('DELETE FROM entry_etymologies'); print('done')\n",
    "# dev_cursor.d('DELETE FROM entry_pos'); print('done')\n",
    "# dev_cursor.d('DELETE FROM entry_definitions'); print('done')\n",
    "# dev_cursor.d('DELETE FROM entry_pronunciations'); print('done')\n",
    "dev_cursor.e('DROP TABLE IF EXISTS entry_etymologies ')\n",
    "dev_cursor.e('CREATE TABLE `entry_etymologies` (`entry_id` int(11) NOT NULL, `wikitext` text COLLATE utf8mb4_bin, `etymology` text COLLATE utf8mb4_bin, PRIMARY KEY (`entry_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin')\n",
    "# dev_conn.commit()\n",
    "# dev_cursor.d('DESCRIBE entry_etymologies')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T12:35:07.792331Z",
     "start_time": "2020-07-24T12:35:07.594565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_cursor.e('SELECT * FROM entry_connections LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:15:07.957739Z",
     "start_time": "2020-07-29T15:15:07.550180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'etymologies', batch_size=50000, **etymologies_dict_list)\n",
    "# del etymologies_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_etymologies['etymology'] = [None]*1447349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:44:40.713269Z",
     "start_time": "2020-07-29T15:44:40.678344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[len(e) for e in entry_etymologies_dict_list.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:38:23.644805Z",
     "start_time": "2020-07-29T17:37:11.623632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'entry_etymologies', many=True, batch_size=50000, **entry_etymologies_dict_list)\n",
    "# del entry_etymologies_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T12:32:51.839741Z",
     "start_time": "2020-07-24T12:29:33.554868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'entry_connections', many=True, batch_size=50000, **entry_connections_dict_list)\n",
    "del entry_connections_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T12:37:55.623255Z",
     "start_time": "2020-07-24T12:35:33.041723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'entry_pos', many=True, batch_size=50000, **entry_pos_dict_list)\n",
    "del entry_pos_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:34:48.181595Z",
     "start_time": "2020-07-24T20:06:33.908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'entry_definitions', many=True, batch_size=50000, **entry_definitions_dict_list)\n",
    "# del entry_definitions_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:03:14.651383Z",
     "start_time": "2020-07-24T20:03:14.510002Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert(dev_cursor, 'entry_pronunciations', many=True, batch_size=50000, **entry_pronunciations_dict_list)\n",
    "del entry_pronunciations_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T23:14:20.658142Z",
     "start_time": "2020-07-24T23:14:20.373151Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:37:07.265876Z",
     "start_time": "2020-07-29T17:37:07.213444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev_cursor.e('SELECT COUNT(*) FROM entry_etymologies')\n",
    "dev_cursor.e('SELECT * FROM entry_etymologies LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:34:48.153322Z",
     "start_time": "2020-07-24T20:06:04.409210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_etymologies_dict_list['etymology'] = multiParseWikitextSentences(entry_etymologies_dict_list['wikitext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T15:06:42.859908Z",
     "start_time": "2020-06-27T15:06:41.891508Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parseTemplates('From {{inh|en|enm|cat}}, {{m|enm|catte}}, from {{inh|en|ang|catt||male cat}}, {{m|ang|catte||female cat}}, from {{inh|en|gem-pro|*kattuz}}.\\nThe Germanic word is generally thought to be from {{der|en|LL.|cattus||domestic cat}} (c. 350, Palladius), from {{der|en|la|catta}} (c. 75 {{small|A.D.}}, Martial), from an {{der|en|afa}} language. This would roughly match how domestic cats themselves spread, as genetic studies suggest they began to spread out of the Near East / Fertile Crescent during the Neolithic (being in Cyprus by 9500 years ago, and Greece and Italy by 2500 years ago), especially after they became popular in Egypt. However, every proposed source word has presented problems. Adolphe Pictet and many subsequent sources refer to Barabra (Nubian) {{m|onw|tr=kaddîska}} and \"Nouba\" (Nobiin) {{m|fia|kadīs}} as possible sources or cognates, but M. Lionel Bender says the Nubian word is a loan from {{noncog|ar|قِطَّة}}. Jean-Paul Savignac suggests the Latin word is from an Egyptian precursor of {{cog|cop|ϣⲁⲩ||tomcat}} suffixed with feminine {{m|egy|-t}}, but John Huehnergard says \"the source [...] was clearly not Egyptian itself, where no analogous form is attested.\"\\nHuehnergard opines it is \"equally likely that the forms might derive from an ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\". Guus Kroonen also considers the word to be native to Germanic (due to morphological alternations) and Northern Europe, and suggests that it might ultimately be borrowed from Uralic, compare {{noncog|se|gađfe||female stoat}} and {{noncog|hu|hölgy||stoat; lady, bride}} from {{noncog|urj-pro|*käďwä||female (of a fur animal)}}.\\nRelated to {{cog|sco|cat}}, {{cog|fy|kat}}, {{cog|frr|kåt}} and {{m|frr|kaat}}, {{cog|nl|kat}}, {{cog|da|kat}}, {{cog|no|katt}}, {{cog|sv|katt}}, {{cog|nds-de|Katt}} and {{m|nds-de|Katte}}, {{cog|de|Katze}}, {{cog|gsw|Chatz}}, {{cog|is|köttur}}, {{cog|af|kat}}, {{cog|la|cattus}}, {{cog|fr|chat}}, {{cog|nrf|cat}}, {{cog|oc|cat}}, {{cog|pt|gato}}, {{cog|es|gato}}, {{cog|rup|cãtush}}, {{cog|gd|cat}}, {{cog|ga|cat}}, {{cog|br|kazh}}, {{cog|cy|cath}}, {{cog|kw|kath}}, as well as {{cog|grc|κάττα}}, {{cog|el|γάτα}}, and from the same ultimate source {{cog|ru|кот}}, {{cog|uk|кіт}}, {{cog|be|кот}}, {{cog|pl|kot}}, {{cog|csb|kòt}}, {{cog|lt|katė}}, and more distantly {{cog|hy|կատու}}, {{cog|eu|katu}}, {{cog|he|חתול|tr=khatúl}}, {{cog|ar|قِطَّة}} alongside dialectal Maghrebi Arabic {{m|ar|قَطُّوس}} (from Berber, probably from Latin).', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2. Mysql(entry_etymologies) => connections array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Text Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:24:18.475368Z",
     "start_time": "2020-07-18T18:24:18.452641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = 'Cf. French'\n",
    "remove_starting_clauses(a)\n",
    "# remove_matching_parens(a)\n",
    "# remove_lone_languages(a)\n",
    "preprocess_etymology(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:24:19.143171Z",
     "start_time": "2020-07-18T18:24:19.120392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "etymology = 'BULLET::::-Cf. banana'\n",
    "etymology = preprocess_etymology(etymology); etymology\n",
    "etymology = etymology.replace(u'\\xa0', u' ').replace('\\n', ' '); etymology\n",
    "etymology = replace_bullets(etymology); etymology\n",
    "etymology = remove_matching_parens(etymology); etymology\n",
    "etymology = remove_lone_wikis(etymology); etymology\n",
    "etymology = replace_cf(etymology); etymology\n",
    "etymology = remove_starting_clauses(etymology); etymology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:24:19.698848Z",
     "start_time": "2020-07-18T18:24:19.678132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Not doing this yet\n",
    "# RE_QUOTES = r\"\\\"(\\w+)\\\"(?![^{]*})\"\n",
    "# test = 'from {{\"test\"}} test {{test|test}} \"in\"'\n",
    "# re.sub(RE_QUOTES, \"{{eeQuote|\\g<1>}}\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T01:39:21.769466Z",
     "start_time": "2020-07-19T01:39:21.740046Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = {'entry_id': 496,'etymology': 'Probably {{m|mkh-okm|hvat}}, from {{m|mkh-okm|hvat}}','entry_number': 3,'word': 'วัด','language_name': 'Thai'}\n",
    "assert get_wikitext_parts_dict(test) == {'{{eeStart|Thai|วัด}}': {'entry_id': 496,'preceding_text': '','wikitype': 'eeStart','place': 0,'following_text': ' : Probably ','following_wikitext_array': ['{{m|mkh-okm|hvat}}']},'{{m|mkh-okm|hvat}}': {'entry_id': 496,'preceding_text': ' : Probably ','wikitype': 'm','place': 1,'preceding_wikitext_array': ['{{eeStart|Thai|วัด}}'],'following_text': ', from ','following_wikitext_array': ['{{_m|mkh-okm|hvat}}']},'{{_m|mkh-okm|hvat}}': {'entry_id': 496,'preceding_text': ', from ','wikitype': 'm','place': 2,'preceding_wikitext_array': ['{{m|mkh-okm|hvat}}']}}\n",
    "assert get_entry_connections(get_wikitext_parts_dict(test)) == ([['{{eeStart|Thai|วัด}}', '{{m|mkh-okm|hvat}}', 'm', 496],['{{m|mkh-okm|hvat}}', '{{m|mkh-okm|hvat}}', 'm', 496]],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:24:23.040546Z",
     "start_time": "2020-07-18T18:24:23.016632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_entry_connections(get_wikitext_parts_dict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Data gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:00:26.981076Z",
     "start_time": "2020-08-01T03:58:11.309230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 140s\n",
    "sql_stmt = \"\"\"\n",
    "SELECT * FROM entry_etymologies ee\n",
    "INNER JOIN entry_connections ec ON ec.entry_id=ee.entry_id\n",
    "INNER JOIN etymologies e on e._id=ec.etymology_id\n",
    "\"\"\"\n",
    "data = dev_cursor.d(sql_stmt); len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T07:00:44.702754Z",
     "start_time": "2020-08-01T07:00:32.899951Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 90s \n",
    "wikitext_part_array = [get_wikitext_parts_dict(entry) for entry in data if entry['wikitext']]\n",
    "list(wikitext_part_array[0].items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:03:39.184640Z",
     "start_time": "2020-08-01T04:02:25.799845Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 36.7 seconds due to json\n",
    "missed_etymologies = []\n",
    "all_connections = []\n",
    "for i, wikitext_parts in enumerate(wikitext_part_array):\n",
    "    if i % 20000 == 0: print(f'\\r{i}/{len(wikitext_part_array)}', end='')\n",
    "    connections, missed_parts = get_entry_connections(wikitext_parts)\n",
    "    \n",
    "    if missed_parts:\n",
    "        missed_etymologies.append(missed_parts)\n",
    "    if connections:\n",
    "        all_connections += connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:03:41.925731Z",
     "start_time": "2020-08-01T04:03:41.851943Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(all_connections), len(missed_etymologies)\n",
    "# missing amount\n",
    "# 99075: update 5, before adding the {{etyl}} bypass\n",
    "# 56616: update 6, after adding the {{etyl}} bypass\n",
    "# 54367: update 7, after adding the removal of \".\", \";\", \":\" phrases in opening lines\n",
    "# 55381: update 8, after early replacing of {{etyl}} and {{inh|-}}\n",
    "# 48623: update 9, after updating cognate text list\n",
    "# 47586: update 10, after updating the single branch text list\n",
    "# 52406: update 11, after updating the order of the etymology text regexes\n",
    "# 47360 : update 11, after fixing lone language regex\n",
    "# 34674 : update 12, after adding a cognates regex\n",
    "# 33729 : update 13, after updating the single branch regex\n",
    "# 37413 : update 14, after fixing the single branch regex to exclude post key word dashes\n",
    "# 35277 : update 15, added several single path etymology items\n",
    "# 34293 : update 16, added some replacement words\n",
    "# 23360 : update 17, flexible cognate if the text is cognate for sure\n",
    "# 31430 : update 18, added replacements for Cf. and Bullet::::-\n",
    "# 21809 : update 19, Many miscellaneous updates\n",
    "# 21632 : update 20, Fixed duplicated wikitext_part entries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:33:17.146969Z",
     "start_time": "2020-07-15T17:33:00.192Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the sentences that are created from the REGEX\n",
    "temp1 = [list(l.items())[0][1].get('following_text','') for l in wikitext_part_array]; temp1[0]\n",
    "temp1_matches = [t for t in temp1 if re.search(RE_FROM, t)]; temp1_matches\n",
    "Counter(temp1_matches).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' : According to Beekes, of '\n",
    "' : From the same source as '\n",
    "' : of '\n",
    "' : First recorded as a given name of Latvians in the end of the 19th century. From ' # period ok?\n",
    "' : Modified from above. Compare '\n",
    "' : According to Beekes, from the same '\n",
    "' : Forms of '\n",
    "' : From a poem by '\n",
    "' : From the book \"'\n",
    "' : Possibly of '\n",
    "' : Equivalent of '\n",
    "' : The kanji spelling is an example of '\n",
    "' : From Magadhi Prakrit, from Old-Indo-Aryan, akin to '\n",
    "' : From the \"műv-\" stem of '\n",
    "' : Usually considered a word of ' (8)\n",
    "' : Related to or derived from '\n",
    "' : One of the variant spellings of Nichols, from Nichol, a '\n",
    "' : From the name of the local tribe, the '\n",
    "' : From \"*teda\", from \"*tendan\", from '\n",
    "' : Taboo of mentioning '\n",
    "' : From its use in \"'\n",
    "' : Use of '\n",
    "' : From Yueyang Lou Ji by '\n",
    "' : Derived from the name \"'\n",
    "' : From \"-er-\" + '\n",
    "' : From From '\n",
    "' : From class 8 '\n",
    "' : From unknown '\n",
    "Stopped at 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T16:51:10.500109Z",
     "start_time": "2020-07-15T16:51:07.161171Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "find_text = ' : From the '\n",
    "temp2 = [list(l.items())[0] for l in wikitext_part_array]; temp2[0]\n",
    "temp2_match = [t for t in temp2 if t[1].get('following_text','')==find_text]; temp2_match[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T22:28:54.233805Z",
     "start_time": "2020-06-30T22:28:52.731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T22:17:41.866888Z",
     "start_time": "2020-07-02T22:17:41.863439Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T23:39:19.151193Z",
     "start_time": "2020-07-02T23:39:17.824751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = [d for d in data if re.search(r'^(\\w+? )+?to {', d['etymology'])]; temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T19:58:58.337224Z",
     "start_time": "2020-07-07T19:58:58.333332Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preprocess_etymology('From the Interlingua-English Dictionary.\\nFrom {{der|ia|en|plantation}}, from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T20:10:39.141288Z",
     "start_time": "2020-07-07T20:10:24.553408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(100,200):\n",
    "    me = missed_etymologies[i][0]; me\n",
    "    if me['entry_id'] <= 5214: continue\n",
    "        \n",
    "        \n",
    "    d = data[me['entry_id']]; d\n",
    "#     d = data[502]; d\n",
    "    de = d['etymology']; de\n",
    "    # print(me['entry_id'], de)\n",
    "    # log_level('d')\n",
    "    # wtpd = get_wikitext_parts_dict(d); wtpd\n",
    "    # cons = get_entry_connections(wtpd); cons\n",
    "    # log_level('w')\n",
    "    # cons\n",
    "    print(de, f\"{d['word']}#{d['language_name']}\", d['entry_id'])\n",
    "    input('continue?')\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T20:10:44.190435Z",
     "start_time": "2020-07-07T20:10:44.187093Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from_str('From the Roman name, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T15:45:40.198784Z",
     "start_time": "2020-07-07T15:45:40.194190Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = 'Attested in {{inh|fr|fro|-}} as {{m|fro|bien tost}}.'\n",
    "bool(re.search(RE_FROM, ' : ' + s))\n",
    "remove_lone_languages('asdf {{der|ja|ltc|sort=けん|-}} asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:21:59.117428Z",
     "start_time": "2020-07-07T06:21:59.107080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Begins with a language # \n",
    "Arabic {{l|ar|نَسْخ|gloss=transcription}} #  نستعليق Arabic 4956\n",
    "\n",
    "# Ensure this doesn't happen\n",
    "Of {{l|en|Istrian}} origin. lima Italian 4874\n",
    "\n",
    "# Acceptable wikipedia pages ('named after...', etc) with {{w|}} at the end\n",
    "Named after the 18th-century Swiss mathematician {{w|Leonhard Euler}} # Euler's totient function English 4663\n",
    "\n",
    "# Cognate\n",
    "The original meaning was \"row,\" \"rank,\" later \"partition,\" possibly related to {{\n",
    "The current spelling was adopted in the 1690s to emulate the spelling but not the pronunciation (at least originally) of the equivalent modern {{cog|fr|quai}}\n",
    "Although formally a perfectly regular form synchronically, it has most likely become to be used as a greeting because of a paronymic contamination with earlier {{cog|la|havĕ}} \n",
    "Coined by G. de la Landelle together with {{m|fr|aviateur}}; from {{suffix|fr|avis|t1=bird|lang1=la|ation}}. aviation French 2931\n",
    "\n",
    "# single path\n",
    "Originated 1595–1605 from {{etyl|LL.|en}} {{m|la|cooperatus||work with}}\n",
    "Deliberate typographical error for {{m|en|typo}}\n",
    "\n",
    "# Improve regex (add to testing) or from strings\n",
    "'Recorded since c.1330 as {{inh|en|enm|pronouncen||to utter, declare officially}}' pronounce English 554\n",
    "'Coined based on {{etyl|la|en}}'\n",
    "                \n",
    "# Uncertain\n",
    "'Translating {{der|la|grc|Βεελζεβούλ}} and {{der|la|he|בעל זבוב||fly-lord|tr=ba‘al-z'būb}}; perhaps a corruption of Beelzebul, meaning \"Lord of the High Place\", with \"-bul\" altered to \"-bub\" to change the meaning to \"Lord of the Flies\". Beelzebub Latin 953'\n",
    "Genova Italian 125\n",
    "'A reduplication of {{ja-r|もし}}'\n",
    "'1922, {{clipping|en|aborigine|nocap=1}}'\n",
    "'Old Swedish \"rote\",'\n",
    "From {{der|ja|ltc|sort=けん|-}} {{ltc-l|兼}}. 兼 Japanese 943\n",
    "Related to {{m|fi|kostua}}, {{cog|izh|kossia}} and {{cog|vot|kõssõa}}. Sense contaminated by the family of {{m|fi|kastaa}}; see {{m|fi|kostua}} for more. kostea Finnish 1043\n",
    "Alteration by association with {{m|en|-ary}} of the {{der|en|fr|axillaire||of the axilla}} axillary English 2831\n",
    "From \"i\"-stem + {{m|la|-cus}}-icus Latin 20\n",
    "\n",
    "# Definitely ignore\n",
    "{{la-IPA|ēvolve}}\n",
    "Coined by {{w|H.G. Wells}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T22:31:00.542176Z",
     "start_time": "2020-07-08T22:31:00.536389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T22:29:33.021987Z",
     "start_time": "2020-07-08T22:29:32.961900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 304455\n",
    "# me = missed_etymologies[i][0]; me\n",
    "# d = data[me['entry_id']]; d\n",
    "d = data[i]; d\n",
    "de = d['etymology']; de\n",
    "# print(me['entry_id'], de)\n",
    "log_level('d')\n",
    "wtpd = get_wikitext_parts_dict(d); wtpd\n",
    "print(wtpd)\n",
    "cons = get_entry_connections(wtpd); cons\n",
    "log_level('w')\n",
    "cons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "elif wikitype in COGNATE_TYPES \\\n",
    "                or (cognate_str(preceding_text) and wikitype in SINGLE_PATH_TYPES):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:35:41.145482Z",
     "start_time": "2020-07-07T06:35:41.140643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "etymology1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T23:39:42.100231Z",
     "start_time": "2020-07-02T23:39:42.091704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T21:09:37.305389Z",
     "start_time": "2020-06-30T21:09:36.885094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parseTemplates('{{af|eo|geometrio|t1=geometry|-a|pos2=adjectival suffix}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T20:53:29.248264Z",
     "start_time": "2020-06-30T20:53:29.065256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v for m in missed_etymologies for v in m if '{{confix|' in v['wikitext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T22:49:46.596743Z",
     "start_time": "2020-06-30T22:49:46.459042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preceding_texts = [v['preceding_text'] for m in missed_etymologies for v in m]; len(preceding_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T20:51:41.633371Z",
     "start_time": "2020-06-30T20:51:41.510379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki_text_errors = [v['wikitext'] for m in missed_etymologies for v in m if v['preceding_text']==' : From ']; len(wiki_text_errors)\n",
    "wiki_text_type_errors = [splitParts(w[2:-2])[0] for w in wiki_text_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T22:49:54.749591Z",
     "start_time": "2020-06-30T22:49:54.619880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# most_common = Counter(wiki_text_type_errors).most_common(); most_common\n",
    "most_common = Counter(preceding_texts).most_common(); most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T04:40:06.875210Z",
     "start_time": "2020-07-07T04:40:06.760613Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'wikitext_part_array: {len(wikitext_part_array)}')\n",
    "print(f'completed_etymologies: {len(wikitext_part_array) - len(missed_etymologies)}')\n",
    "print(f'missed_etymologies:  {len(missed_etymologies)}')\n",
    "print(f'all_connections: {len([a for a in all_connections if a])}')\n",
    "print(f'missed_parts:  {len(missed_parts)}')\n",
    "\n",
    "\n",
    "print(all_connections[199999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T15:58:28.642387Z",
     "start_time": "2020-06-30T15:58:28.637760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry['etymology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T15:53:57.170044Z",
     "start_time": "2020-06-30T15:53:57.166582Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(json.dumps(wikitext_parts, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T18:26:45.434716Z",
     "start_time": "2020-06-27T18:26:45.430131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#         print(s,e)\n",
    "#         res += wikitext[cur:s] + self.expandTemplate(wikitext[s + 2:e - 2])\n",
    "#     cur = e\n",
    "#     leftover\n",
    "#     res += wikitext[cur:]\n",
    "    # logging.debug('%*sexpand> %s', self.frame.depth, '', res)\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T23:46:18.700087Z",
     "start_time": "2020-06-30T23:46:18.696643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:27:58.396054Z",
     "start_time": "2020-07-01T01:27:58.389309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:14:21.641077Z",
     "start_time": "2020-07-01T04:14:21.633284Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_entry_connections(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T21:48:39.116206Z",
     "start_time": "2020-07-02T21:48:39.090268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0 = {\n",
    "    '{{eeStart}}': {'preceding_text':'','wikitype':'eeStart','place': 0,'following_text':' : From ','following_wikitext_array': ['{{inh|1}}']},\n",
    "    '{{inh|1}}': {'entry_id': 0,'preceding_text': ' : From ','wikitype': 'inh','place': 1,'preceding_wikitext_array': ['{{eeStart}}'],'following_text': ', from ','following_wikitext_array': ['{{inh|2}}']},\n",
    "    '{{inh|2}}': {'entry_id': 0,'preceding_text': ', from ','wikitype': 'inh','place': 2,'preceding_wikitext_array': ['{{inh|1}}'],'following_text': '. Germanic cognates include ','following_wikitext_array': ['{{cog|1}}']},\n",
    "    '{{cog|1}}': {'entry_id': 0,'preceding_text': '. Germanic cognates include ','wikitype': 'cog','place': 3,'preceding_wikitext_array': ['{{inh|2}}'],'following_text': ' (','following_wikitext_array': ['{{cog|2}}']},\n",
    "}\n",
    "assert get_entry_connections(t0) == ([['{{eeStart}}', '{{inh|1}}', 'inh'],['{{inh|1}}','{{inh|2}}','inh'],['{{eeStart}}', '{{cog|1}}', 'cog']], [])\n",
    "t1 = {'{{eeStart}}': {'preceding_text': '','wikitype': 'eeStart','following_text': ' : From ','following_wikitext_array': ['{{inh|1}}']},\n",
    "     '{{inh|1}}': {'preceding_text': ' : From ','wikitype': 'inh','preceding_wikitext_array': ['{{eeStart}}'],'following_text': ', ','following_wikitext_array': ['{{m|1}}']},\n",
    "     '{{m|1}}': {'preceding_text':', ','wikitype':'m','preceding_wikitext_array': ['{{inh|1}}'],'following_text': ', borrowed from ','following_wikitext_array': ['{{bor|1}}']},\n",
    "     '{{bor|1}}': {'preceding_text': ', borrowed from ','wikitype': 'bor','preceding_wikitext_array': ['{{m|1}}'],'following_text': ', noun of action from perfect passive participle ','following_wikitext_array': ['{{m|2}}']},\n",
    "     '{{m|2}}': {'preceding_text': ', noun of action from perfect passive participle ','wikitype': 'm','preceding_wikitext_array': ['{{bor|1}}'],'following_text': ', from verb ','following_wikitext_array': ['{{m|3}}']},\n",
    "     '{{m|3}}': {'preceding_text': ', from verb ','wikitype': 'm','preceding_wikitext_array': ['{{m|2}}'],'following_text': ', + noun of action suffix ','following_wikitext_array': ['{{m|4}}']},\n",
    "     '{{m|4}}': {'preceding_text': ', + noun of action suffix ','wikitype': 'm','preceding_wikitext_array': ['{{m|3}}']}}\n",
    "assert get_entry_connections(t1) == ([['{{eeStart}}', '{{inh|1}}', 'inh'],['{{eeStart}}', '{{m|1}}', 'm'],['{{m|1}}', '{{bor|1}}', 'bor'],['{{inh|1}}', '{{bor|1}}', 'bor'],['{{bor|1}}', '{{m|2}}', 'm'],['{{m|2}}', '{{m|3}}', 'm'],['{{m|2}}', '{{m|4}}', 'm']],[])\n",
    "t2 = {'{{eeStart}}': {'preceding_text': '','wikitype': 'eeStart','following_text': ' : From ','following_wikitext_array': ['{{inh|en|enm|techere}}']}, \n",
    "      '{{inh|en|enm|techere}}': {'preceding_text': ' : From ',  'wikitype': 'inh','preceding_wikitext_array': ['{{eeStart}}'],'following_text': ', equivalent to ','following_wikitext_array': ['{{suffix|en|teach|er}}']},\n",
    "      '{{suffix|en|teach|er}}': {'preceding_text': ', equivalent to ','wikitype': 'suffix','preceding_wikitext_array': ['{{inh|en|enm|techere}}'],'following_text': '. More at ','following_wikitext_array': ['{{l|en|teach}}']},\n",
    "      '{{l|en|teach}}': {'preceding_text': '. More at ','wikitype': 'l','preceding_wikitext_array': ['{{suffix|en|teach|er}}']}}\n",
    "assert get_entry_connections(t2) == ([['{{eeStart}}', '{{inh|en|enm|techere}}', 'inh'],['{{eeStart}}', '{{suffix|en|teach|er}}', 'suffix'],['{{eeStart}}', '{{l|en|teach}}', 'cog']],[])\n",
    "t3 = {'{{eeStart|English|trink}}': {'entry_id': 2296,  'preceding_text': '',  'wikitype': 'eeStart',  'place': 0,  'following_text': ' : From ',  'following_wikitext_array': ['{{inh|en|enm|treinekys}}']}, '{{inh|en|enm|treinekys}}': {'entry_id': 2296,  'preceding_text': ' : From ',  'wikitype': 'inh',  'place': 1,  'preceding_wikitext_array': ['{{eeStart|English|trink}}'],  'following_text': ' or ',  'following_wikitext_array': ['{{m|enm|trynk}}']}, '{{m|enm|trynk}}': {'entry_id': 2296,  'preceding_text': ' or ',  'wikitype': 'm',  'place': 2,  'preceding_wikitext_array': ['{{inh|en|enm|treinekys}}'],  'following_text': ', but earlier origin is ',  'following_wikitext_array': ['{{unk|en|nocap=1}}']}, '{{unk|en|nocap=1}}': {'entry_id': 2296,  'preceding_text': ', but earlier origin is ',  'wikitype': 'unk',  'place': 3,  'preceding_wikitext_array': ['{{m|enm|trynk}}'],  'following_text': '. Attested in ',  'following_wikitext_array': ['{{w|Anglo-Norman}}']}, '{{w|Anglo-Norman}}': {'entry_id': 2296,  'preceding_text': '. Attested in ',  'wikitype': 'w',  'place': 4,  'preceding_wikitext_array': ['{{unk|en|nocap=1}}']}}\n",
    "assert get_entry_connections(t3)[0] == [['{{eeStart|English|trink}}', '{{inh|en|enm|treinekys}}', 'inh'],['{{eeStart|English|trink}}', '{{m|enm|trynk}}', 'm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T21:35:08.190275Z",
     "start_time": "2020-07-02T21:35:08.185560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T21:31:57.634719Z",
     "start_time": "2020-07-02T21:31:57.613736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('d')\n",
    "get_entry_connections(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:15:20.572363Z",
     "start_time": "2020-07-01T04:15:20.567179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_entry_connections(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:30:08.658746Z",
     "start_time": "2020-07-01T00:30:08.512295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = [d for d in data if '}, {' in d['etymology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:30:10.841671Z",
     "start_time": "2020-07-01T00:30:10.835675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e1 = test[100];e1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:23:27.632218Z",
     "start_time": "2020-07-01T01:23:27.625574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e1['etymology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T04:14:10.718116Z",
     "start_time": "2020-07-01T04:14:10.714126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:35:26.960970Z",
     "start_time": "2020-07-01T01:35:26.955784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te1 = get_wikitext_parts_dict(e1); te1\n",
    "get_entry_connections(te1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T20:27:33.641822Z",
     "start_time": "2020-07-07T20:27:33.615177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_entry_connections(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 3. connections array => Mysql(connections) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:56:57.145599Z",
     "start_time": "2020-08-01T03:56:56.964894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Put the connection in the function so that it calls for the language_dict? Make it an optional input for the \n",
    "get Node connections since it might not need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:57:10.240069Z",
     "start_time": "2020-08-01T03:57:10.212977Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One idea is to put this function inside the place I use it to get the contexts right\n",
    "def getOrCreateIdWithDict(word:str, lang:str, cursor, debug_str=None):\n",
    "\t\"\"\"\n",
    "\tParameters\n",
    "\t==========\n",
    "\tword (str): the word to check. This fn will clean and transliterate, so no need to before\n",
    "\tlang (str): the language to check\n",
    "\n",
    "\tGlobal Parameters\n",
    "\t=================\n",
    "\twl_2_id (dict): The dictionary of { (word, lang): id, ...}\n",
    "\tnext_wl_2_id (int): The first unused _id in wl_2_id\n",
    "\n",
    "\tGet the _id of a word,language combo from dict of table etymlogies\n",
    "\tIf it doesn't exist create a new id based on the max value\n",
    "\t\"\"\"\n",
    "\t# Manage the global variables\n",
    "\tglobal wl_2_id\n",
    "\tglobal next_wl_2_id \n",
    "\tglobal unmatched_words\n",
    "\n",
    "\ttry:\n",
    "\t\tunmatched_words\n",
    "\texcept NameError:\n",
    "\t\tunmatched_words = []\n",
    "\n",
    "\ttry:\n",
    "\t\twl_2_id\n",
    "\t\tnext_wl_2_id # Assume this is created if wl_2_id is\n",
    "\texcept NameError:\n",
    "\t\tprint('Creating wl_2_id, may take ~1 minute')\n",
    "\t\twl_2_id, next_wl_2_id = make_wl_2_id_values(cursor)\n",
    "\n",
    "\t# Handle the actual function\n",
    "\tword = clean_word(word) # removes asterisk and other issues\n",
    "\n",
    "\ttry:\t\n",
    "\t\t_id = wl_2_id[(word, lang)]\n",
    "\texcept KeyError:\n",
    "\t\tword = remove_diacritics(word)\n",
    "\t\ttry:\n",
    "\t\t\t_id = wl_2_id[(word, lang)]\n",
    "\t\texcept KeyError:\n",
    "\t\t\t_id = next_wl_2_id\n",
    "\t\t\twl_2_id[(word, lang)] = next_wl_2_id\n",
    "\t\t\tif debug_str:\n",
    "\t\t\t\tlogging.debug(debug_str)\n",
    "\t\t\tnext_wl_2_id += 1\n",
    "\t\t\tunmatched_words += [[_id, word, lang]]\n",
    "\n",
    "\treturn _id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:38:32.285150Z",
     "start_time": "2020-08-01T02:38:32.038251Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "getConnectionsForID(dev_cursor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:39:00.018844Z",
     "start_time": "2020-08-01T02:38:59.951089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wl_2_id[('acrocarpous','English')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:38:01.152431Z",
     "start_time": "2020-08-01T02:38:01.061099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev_cursor.e('SELECT * FROM etymologies WHERE _id=1')\n",
    "# dev_cursor.d('SELECT * FROM entry_connections WHERE etymology_id=1 ')\n",
    "dev_cursor.d('SELECT * FROM entry_etymologies WHERE entry_id=225005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T01:58:26.691278Z",
     "start_time": "2020-08-01T01:58:26.625359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# values = [[n['word'], n['language']] for conn in nodeConnections for n in conn if type(n) != int]; values\n",
    "# cursor.d('SELECT word, language_name, _id from etymologies WHERE word=%s AND language_name=%s', many=True, values=[[n['word'], n['language']] for conn in nodeConnections for n in conn if type(n) != int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:57:25.605271Z",
     "start_time": "2020-08-01T03:57:24.956693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "language_dict = create_language_dict(dev_cursor); language_dict['qfa-adm-pro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:04:53.666768Z",
     "start_time": "2020-08-01T04:04:23.529488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nodeConnections = []\n",
    "for i, connection in enumerate(all_connections):\n",
    "    if i % 50000 == 0: print(f'\\r{i}/{len(all_connections)}', end='')\n",
    "    nodeConnections += getNodeConnections(connection, dev_cursor)\n",
    "nodeConnections[2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T02:29:36.852394Z",
     "start_time": "2020-08-01T02:29:36.781640Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nodeConnections[2003]\n",
    "# getIndexForWordAndLanguage('μόνος', 'Ancient Greek', data)\n",
    "# getConnectionsForIndex(295123, dev_cursor, data)\n",
    "# [d for d in data if d['word'] == 'conniption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T13:12:49.752179Z",
     "start_time": "2020-07-09T13:11:56.138361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checking the word and languages versus expand/parse Templates\n",
    "# for i, (desc, root, conn_type, index) in enumerate(all_connections):\n",
    "#     if i <= 4061: continue\n",
    "#     template = root\n",
    "        \n",
    "#     typen, *parts = splitParts(template[2:-2])\n",
    "    \n",
    "#     if typen == 'eeStart': continue\n",
    "#     if typen == 'cog': continue\n",
    "    \n",
    "#     try:\n",
    "#         myResult = getNodesFromTemplate(template, 'root', language_dict)\n",
    "#     except EmptyWordOrLanguageError as e:\n",
    "#         print(f'\\rEMPTY WORD on {i}', root, end='\\n')\n",
    "#         continue\n",
    "        \n",
    "#     if typen in ['m', 'l']:\n",
    "#         o1 = f\"{myResult[0]['word']}\"\n",
    "#     elif typen in ['suffix', 'suf']:\n",
    "#         o1 = f'{myResult[0][\"word\"]} + -{myResult[1][\"word\"]}'\n",
    "#     elif typen in ['prefix', 'pre']:\n",
    "#         o1 = f'{myResult[0][\"word\"]}- + {myResult[1][\"word\"]}'\n",
    "#     elif typen in ['affix', 'af', 'compound', 'com']:\n",
    "#         o1 = ' + '.join(r['word'] for r in myResult)\n",
    "#     elif typen in ['ja-r']:\n",
    "#         o1 = f'{myResult[0][\"word\"]}'\n",
    "#     else:\n",
    "#         o1 = f\"{myResult[0]['language']} {myResult[0]['word']}\"\n",
    "#     o2 = remove_matching_parens(parseTemplates(template, session=session)) # remove parens to match\n",
    "        \n",
    "#     if o1 != o2.replace('\\u200e', ''):\n",
    "#         if typen == 'inh' and parts[2] == myResult[0]['word']: continue\n",
    "#         print(f'\\rERROR on {i}', o1, o2, o1 == o2, root, end='\\n')\n",
    "#     else:\n",
    "#         print(f'\\r{i}/{len(all_connections)}', end='')\n",
    "#         pass\n",
    "# #         print(f'{i} ok!', o1, o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:57:27.834564Z",
     "start_time": "2020-08-01T03:57:27.806873Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert getNodesFromTemplate('{{suf|en|tenuis|ous|lang1=la}}', 'root', language_dict) == [{'word':'tenuis','language':'Latin'},{'word':'ous','language':'English'}]\n",
    "assert getNodesFromTemplate('{{w|Nathan Fillion}}', 'root', language_dict) == [{'word': 'Nathan Fillion', 'language': 'English'}]\n",
    "assert getNodesFromTemplate('{{m|la||*brabus}}', 'root', language_dict) == [{'word': '*brabus', 'language': 'Latin'}]\n",
    "assert getNodesFromTemplate('{{ja-r|もし}}', 'root', language_dict) == [{'word': 'もし', 'language': 'Japanese'}]\n",
    "assert getNodesFromTemplate('{{der|en|la|vocātiō|vocātiō}}', 'root', language_dict) == [{'word': 'vocātiō', 'language': 'Latin'}]\n",
    "assert getNodesFromTemplate('{{bor|sw|acx|kittāra|t=sabre}}', 'root', language_dict) == [{'word': 'kittāra', 'language': 'Omani Arabic'}]\n",
    "assert getNodesFromTemplate('{{borrowed|1=la|2=grc|3=Εὐμενίδες|gloss=the gracious ones|g=f-p}}', 'root', language_dict) == [{'word': 'Εὐμενίδες', 'language': 'Ancient Greek'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:45:03.859111Z",
     "start_time": "2020-07-18T18:45:03.831718Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# expandTemplate('{{w|Kamil Zvelebil|K. V. Zvelebil}}')\n",
    "# template = '{{inh|ja|ojp|-|sort=けさ}}'\n",
    "# parseTemplates(template, session=session)\n",
    "# remove_matching_parens(parseTemplates(template, session=session))\n",
    "# getNodesFromTemplate(template, 'root', language_dict)\n",
    "# template = '{{ja-r|もし}}'\n",
    "# [d for d in data if template in d['etymology']]\n",
    "# template='{{m|lij|o||the|g=m-s|pos=definite article}}'\n",
    "# getNodesFromTemplate(template, 'root', language_dict), template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# figure out why this broke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T17:53:18.683798Z",
     "start_time": "2020-07-08T17:53:17.038164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for desc, root, conn_type in all_connections[:]:\n",
    "#     if conn_type == 'cog': continue # Ignoring cognates for now\n",
    "#     if desc.startswith('{{ar-root|'):# and '=' in desc: \n",
    "#         print(desc)\n",
    "#         try:\n",
    "#             getWordAndLanguageFromTemplate(desc, language_dict)\n",
    "#             print(getWordAndLanguageFromTemplate(desc, language_dict))\n",
    "#         except:\n",
    "#             print(f'Could not get info for {desc}')\n",
    "#     desc_parts = splitParts(desc[2:-2])\n",
    "#     desc_parts = splitParts(desc[2:-2])\n",
    "#     if (desc.startswith('{{eeStart|')):\n",
    "#         print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T17:54:02.987832Z",
     "start_time": "2020-07-08T17:54:01.143770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [d for d in data if '{{ar-root|س|م|ع}}' in d['etymology']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Upload to Mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:21:34.060007Z",
     "start_time": "2020-08-01T04:21:33.870135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:05:25.432964Z",
     "start_time": "2020-08-01T04:05:25.358503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(nodeConnections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:06:32.083457Z",
     "start_time": "2020-08-01T04:05:29.770766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 65s\n",
    "entry_id_2_number = {d['entry_id']: d['entry_number'] for d in dev_cursor.d('SELECT entry_id, entry_number FROM entry_connections;')}\n",
    "len(entry_id_2_number), entry_id_2_number[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:08:35.816520Z",
     "start_time": "2020-08-01T04:07:13.127010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 90s\n",
    "unmatched_words = []\n",
    "wl_2_id, next_wl_2_id = make_wl_2_id_values(dev_cursor); next_wl_2_id\n",
    "# next_wl_2_id = max(wl_2_id.values()) + 1 # 7934778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:08:35.927558Z",
     "start_time": "2020-08-01T04:08:35.828830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "next_wl_2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:08:42.729714Z",
     "start_time": "2020-08-01T04:08:35.935202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 20s, Get data from section 2, data gather\n",
    "entry_id_2_word = {d['entry_id']: f\"{d['word']}#{d['language_name']}\" for d in data}; len(entry_id_2_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:06:39.495287Z",
     "start_time": "2020-08-01T03:06:39.427295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nodeConnections[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:09:17.145815Z",
     "start_time": "2020-08-01T04:08:53.685991Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 32s\n",
    "# TODO need to find and match the words with \"-\" at the beginning or end\n",
    "\n",
    "log_level('d')\n",
    "roots = []; descs = []; table_sources = []; entry_numbers = [];\n",
    "\n",
    "for i, (desc, root, entry_id) in enumerate(nodeConnections):\n",
    "#     debug_str = f\"no:{entry_id_2_number[entry_id]} {entry_id_2_word[entry_id]}, {desc['word']}&{desc['language']}, {entry_id}\"\n",
    "    desc_id = getOrCreateIdWithDict(desc['word'], desc['language'], dev_cursor, debug_str=None)\n",
    "    \n",
    "#     debug_str = f\"no:{entry_id_2_number[entry_id]} {entry_id_2_word[entry_id]}, {root['word']}&{root['language']}, {entry_id}\"\n",
    "    root_id = getOrCreateIdWithDict(root['word'], root['language'], dev_cursor, debug_str=None)\n",
    "    \n",
    "    roots.append(root_id)\n",
    "    descs.append(desc_id)\n",
    "    table_sources.append(entry_id)\n",
    "    entry_numbers.append(entry_id_2_number[entry_id])\n",
    "len(unmatched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:09:17.281613Z",
     "start_time": "2020-08-01T04:09:17.162395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get_debug_str = lambda x: f\"no:{entry_id_2_number[x[0]]} {entry_id_2_word[x[0]]}, {desc['word']}&{desc['language']}, {entry_id}\"\n",
    "# [u*, u[0]] for u in unmatched_words]\n",
    "# unmatched_words\n",
    "len(unmatched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T01:14:42.987871Z",
     "start_time": "2020-07-19T01:14:42.958092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del wl_2_id\n",
    "# del next_wl_2_id \n",
    "# del unmatched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:34:58.423434Z",
     "start_time": "2020-08-01T03:34:53.012677Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# insert unmatched words\n",
    "_ids,words,langs = zip(*unmatched_words)\n",
    "value_dict = {'_id':_ids, 'word':words,'language_name':langs}\n",
    "insert(\n",
    "    dev_cursor, \n",
    "    'etymologies', \n",
    "    many=True,\n",
    "    **value_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T03:35:04.741075Z",
     "start_time": "2020-08-01T03:35:04.632656Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T01:46:44.924036Z",
     "start_time": "2020-07-19T01:46:44.864092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "getConnectionsForID(dev_cursor, 23683)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:30:36.242385Z",
     "start_time": "2020-08-01T04:30:35.720109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev_cursor.d('SELECT * FROM etymologies WHERE _id=7753025')\n",
    "# dev_cursor.d('SELECT * FROM etymologies WHERE _id=297736')\n",
    "# dev_cursor.d('SELECT * FROM etymologies WHERE _id=7760863')\n",
    "# dev_cursor.e('SELECT table_source FROM connection_sources WHERE root=7760863 AND descendant=297736')\n",
    "# dev_cursor.e('SELECT * FROM entry_etymologies WHERE entry_id=107282')\n",
    "# dev_cursor.d('SELECT * FROM entry_connections WHERE entry_id=107282')\n",
    "# dev_cursor.d('SELECT COUNT(*) FROM connection_sources')\n",
    "# dev_cursor.d('SELECT COUNT(*) FROM connections')\n",
    "# dev_cursor.d('DELETE FROM connection_sources') # ~3.5 min\n",
    "# dev_cursor.d('DELETE FROM connections') # ~4 min\n",
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:18:27.233499Z",
     "start_time": "2020-08-01T04:18:20.967315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[[i,t] for i,t in enumerate(table_sources) if t==254361]\n",
    "roots[383842]\n",
    "[w for w in wl_2_id.items() if w[1] == 7788599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:18:31.864566Z",
     "start_time": "2020-08-01T04:18:31.827868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(unmatched_words)\n",
    "# 700k with nothing, \n",
    "# 204381 with always transliterate some languages\n",
    "# 141850 with check transliterration if needed (20s) now 150s\n",
    "# 79841 with fn check transliteration and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:18:37.176295Z",
     "start_time": "2020-08-01T04:18:35.218823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(roots), len(descs), len(table_sources), len(entry_numbers), list(zip(roots, descs, table_sources, entry_numbers))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PROBLEMS:\n",
    "No _id for lexico - English, new _id = 7741531 (needs to be a prefix with '-')\n",
    "No _id for graphy - English, new _id = 7741532 (needs to be a suffix with '-')\n",
    "Reconstruction:Proto-Indo-Iranian/Hr̥ȷ́ipyás\n",
    "What is happening with reconstructions?\n",
    "Hr̥ȷ́ipyás \n",
    "\"Kallyobrix\"\n",
    "abstraction - Middle French\n",
    "वात#Etymology_1\n",
    "वात#Etymology_2\n",
    "ord ,  ordd, \n",
    "jen(u)ārius\n",
    "fail ,  faus\n",
    "fallō ,  fallis\n",
    "(s)kh₃tos\n",
    "K .  V . \n",
    "ǁkoaah\n",
    "wikipedia : Averroes\n",
    "c .\n",
    "oeil ~ oil ~ uel\n",
    "( mensis )  Māius\n",
    "rēx ,  rēgem\n",
    "quid nunc ?\n",
    "\n",
    "Etymology problem:\n",
    "The supposed name of a lost girl on the day of 2013 Bohol earthquake and used as a humorous explanation to the resulting tsunami scare in Cebu.\n",
    "\n",
    "pneumonoultramicroscopicsilicovolcanoconiosis#English is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:23:34.290432Z",
     "start_time": "2020-08-01T04:22:08.563960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Connection sources 1.5min\n",
    "insert(\n",
    "    dev_cursor, \n",
    "    'connection_sources', \n",
    "    many=True, \n",
    "    **{\n",
    "        'root':roots,\n",
    "        'descendant':descs,\n",
    "        'table_source':table_sources,\n",
    "        'entry_number':entry_numbers\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:23:36.521248Z",
     "start_time": "2020-08-01T04:23:35.894695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:30:04.234449Z",
     "start_time": "2020-08-01T04:29:05.045409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Connection data 1 min\n",
    "# make a set for roots, desc\n",
    "conn_set = set(zip(roots,descs))\n",
    "roots_set = [s[0] for s in conn_set]\n",
    "descs_set = [s[1] for s in conn_set]\n",
    "\n",
    "insert(\n",
    "    dev_cursor, \n",
    "    'connections', \n",
    "    ignore=True,\n",
    "    many=True, \n",
    "    **{\n",
    "        'root':roots_set,\n",
    "        'descendant':descs_set,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Toubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:39:21.367787Z",
     "start_time": "2020-08-01T04:39:21.284930Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "getConnectionsForID(dev_cursor, 89775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:43:32.743752Z",
     "start_time": "2020-08-01T04:43:32.717727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "remove_diacritics('-ικός')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T04:42:40.872590Z",
     "start_time": "2020-08-01T04:42:40.744526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word='-ικός'#'ῐκός'#'-ῐκός'\n",
    "lang= 'Ancient Greek'#'English'\n",
    "# _id = 9\n",
    "_id = next(iter(dev_cursor.e(f'SELECT _id FROM etymologies WHERE word=\"{word}\" AND language_name=\"{lang}\"')),'None'); _id\n",
    "# details = get_details(dev_conn, _id); details\n",
    "# dev_cursor.d(f'SELECT * FROM connection_sources cs INNER JOIN etymologies e ON e._id=cs.root WHERE descendant={_id}')\n",
    "# dev_cursor.d(f'SELECT * FROM connection_sources cs INNER JOIN etymologies e ON e._id=cs.descendant WHERE root={_id}')\n",
    "# dev_cursor.d(f'SELECT * FROM connection_sources cs WHERE root={_id}')\n",
    "# dev_cursor.d(f'SELECT * FROM entry_etymologies WHERE entry_id=623529')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:43:29.509445Z",
     "start_time": "2020-07-19T00:43:28.915784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[d for d in descs if d==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:44:14.634656Z",
     "start_time": "2020-07-19T00:44:14.585657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev_cursor.e('SELECT * FROM etymologies WHERE word=\"afraidness\"') # 9\n",
    "# dev_cursor.e('SELECT * FROM connections WHERE descendant=9')\n",
    "# dev_cursor.e('SELECT * FROM connection_sources WHERE descendant=9')\n",
    "# dev_cursor.e('SELECT * FROM connections LIMIT 1')\n",
    "# dev_cursor.e('SELECT * FROM connection_sources LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:40:50.300594Z",
     "start_time": "2020-07-19T00:40:49.867732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:49:05.346971Z",
     "start_time": "2020-07-19T00:49:05.219062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[d for d in data if d['word']=='frei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:42:55.924436Z",
     "start_time": "2020-07-19T00:42:55.871469Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stage_cursor.e('SELECT * FROM connection_sources WHERE descendant=9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:42:42.357552Z",
     "start_time": "2020-07-19T00:42:42.180288Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u = os.environ['RDS_ETY_USER']\n",
    "p = os.environ['RDS_ETY_PASSWORD']\n",
    "h = os.environ['RDS_ETY_HOST']\n",
    "# dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)\n",
    "# stage_conn, stage_cursor = connect('etymology_explorer_staging', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### More troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:54:37.029056Z",
     "start_time": "2020-07-19T00:54:37.001787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T00:54:39.724052Z",
     "start_time": "2020-07-19T00:54:39.697844Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "getConnectionsForIndex(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T01:00:41.618609Z",
     "start_time": "2020-07-19T01:00:41.477503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.environ['ETY_CON_SRC_TABLE'] = 'connection_sources'\n",
    "get_tree(dev_conn, _id=1504940, compression=0, details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4. Cleanup (remove unused/weird words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:31:11.123158Z",
     "start_time": "2020-08-05T17:31:11.091132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a,b = wp.make_wl_2_id_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:33:09.462185Z",
     "start_time": "2020-08-05T17:31:35.600722Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = dev_cursor.d('SELECT * FROM etymologies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:39:30.893892Z",
     "start_time": "2020-08-05T17:39:30.862652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(word_lang_pairs), len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:37:31.836234Z",
     "start_time": "2020-08-05T17:37:16.817318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Problem words\n",
    "bad = [(t['word'], t['language_name']) for t in temp if '\\u200e' in t['word']]\n",
    "word_lang_pairs = set((w['word'], w['language_name'])  for w in temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:39:03.313132Z",
     "start_time": "2020-08-05T17:39:03.103310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fixable = [b for b in bad if (b[0].replace('\\u200e',''), b[1]) in word_lang_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T17:41:22.751558Z",
     "start_time": "2020-08-05T17:41:22.676337Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter(fixable).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cursor.e('DROP TABLE entry_etymologies')\n",
    "# dev_cursor.e('SHOW CREATE TABLE entry_connections')\n",
    "# test_cursor.e('CREATE TABLE `entry_etymologies` (`entry_id` int(11) NOT NULL, `wikitext` text COLLATE utf8mb4_bin, `etymology` text COLLATE utf8mb4_bin, PRIMARY KEY (`entry_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin')\n",
    "# test_cursor.e('CREATE TABLE `entry_connections` (\\n  `etymology_id` int(11) DEFAULT NULL,\\n  `entry_id` int(11) DEFAULT NULL,\\n  `entry_number` int(11) NOT NULL,\\n  UNIQUE KEY `entry_id` (`entry_id`),\\n  KEY `ety_id_to_entry` (`etymology_id`),\\n  KEY `entry_number` (`entry_number`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T04:59:01.655243Z",
     "start_time": "2020-08-12T04:59:01.600164Z"
    }
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(2013, 'Lost connection to MySQL server during query')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3230507c1972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_cursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM etymologies LIIMIT 100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/git/dgn_utils_module/dgnutils/__init__.py\u001b[0m in \u001b[0;36me\u001b[0;34m(self, sql_stmt, values, many)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mexecute_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmany\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;31m# Choose executemany or execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_stmt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_stmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msql_stmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DELETE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INSERT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UPDATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m             \u001b[0mfirst_packet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0mpacket_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m             \u001b[0;31m#if DEBUG: dump_packet(packet_header)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             raise err.OperationalError(\n\u001b[0;32m--> 707\u001b[0;31m                 CR.CR_SERVER_LOST, \"Lost connection to MySQL server during query\")\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2013, 'Lost connection to MySQL server during query')"
     ]
    }
   ],
   "source": [
    "test_cursor.e('SELECT * FROM etymologies LIIMIT 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T02:15:02.122453Z",
     "start_time": "2020-08-12T02:15:01.971508Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using database: etymology_explorer_test\n"
     ]
    }
   ],
   "source": [
    "log_level('d')\n",
    "wp = WikiProcessor(\n",
    "    '/Users/nish/development/git/wikiextractor/', \n",
    "    channel='test', \n",
    "    output_dir='output_test/',\n",
    "    cache_dir=None,\n",
    "    dump_file_name='test.xml',\n",
    "    store_intermediates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T02:15:17.646585Z",
     "start_time": "2020-08-12T02:15:02.124910Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Recreating all tables EXCEPT []\n",
      "DEBUG:root:Recreating table ancestors\n",
      "DEBUG:root:Recreating table common_words\n",
      "DEBUG:root:Recreating table connection_sources\n",
      "DEBUG:root:Recreating table connections\n",
      "DEBUG:root:Recreating table entry_connections\n",
      "DEBUG:root:Recreating table entry_definitions\n",
      "DEBUG:root:Recreating table entry_etymologies\n",
      "DEBUG:root:Recreating table entry_pos\n",
      "DEBUG:root:Recreating table entry_pronunciations\n",
      "DEBUG:root:Recreating table etymologies\n",
      "DEBUG:root:Recreating table kin\n",
      "DEBUG:root:Recreating table languages\n",
      "/Users/nish/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py:170: Warning: (1831, \"Duplicate index 'language_name_index' defined on the table 'etymology_explorer_test.languages'. This is deprecated and will be disallowed in a future release.\")\n",
      "  result = self._query(query)\n",
      "DEBUG:root:Recreating table merged_etymologies\n",
      "DEBUG:root:Recreating table permanent_errors\n",
      "DEBUG:root:Recreating table progeny\n",
      "DEBUG:root:Recreating table random_etymologies\n",
      "DEBUG:root:Recreating table transliterations\n",
      "DEBUG:root:Recreating table wiktionary_page_dne\n",
      "DEBUG:root:Inserting languages data due to TEST\n",
      "INFO:root:Creating wl_2_id dictionary...\n",
      "INFO:root:Processing wikiextractor directory /Users/nish/development/git/wikiextractor/output_test/\n",
      "DEBUG:root:Processing wikiextractor directory: AA\n",
      "INFO:root:Creating mysql data to insert\n",
      "INFO:root:Found 4008 new connections to insert\n",
      "INFO:root:Found 2469 new etymologies to insert\n",
      "INFO:root:Found 4011 new pos to insert\n",
      "INFO:root:Found 2002 new pronunciations to insert\n",
      "INFO:root:Found 7211 new definitions to insert\n",
      "INFO:root:Converting wikitext into text...\n",
      "DEBUG:root:Generating list of used wikitexts...\n",
      "DEBUG:root:There are 2220 to gather...\n",
      "INFO:root:Generating groups of wikitexts for api calls over 23 steps...\n",
      "INFO:root:Performing API calls on wikitext_groupings over 1 steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Step 0\r",
      "Step 1\r",
      "Step 2\r",
      "Step 3\r",
      "Step 4\r",
      "Step 5\r",
      "Step 6\r",
      "Step 7\r",
      "Step 8\r",
      "Step 9\r",
      "Step 10\r",
      "Step 11\r",
      "Step 12\r",
      "Step 13\r",
      "Step 14\r",
      "Step 15\r",
      "Step 16\r",
      "Step 17\r",
      "Step 18\r",
      "Step 19\r",
      "Step 20\r",
      "Step 21\r",
      "Step 22\r",
      "Step 0/1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Replacing wikitext in the sentences...\n",
      "DEBUG:root:Generating list of used wikitexts...\n",
      "DEBUG:root:There are 313 to gather...\n",
      "INFO:root:Generating groups of wikitexts for api calls over 4 steps...\n",
      "INFO:root:Performing API calls on wikitext_groupings over 1 steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220 results\n",
      "\r",
      "Step 0\r",
      "Step 1\r",
      "Step 2\r",
      "Step 3\r",
      "Step 0/1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Replacing wikitext in the sentences...\n",
      "DEBUG:root:Generating list of used wikitexts...\n",
      "DEBUG:root:There are 7043 to gather...\n",
      "INFO:root:Generating groups of wikitexts for api calls over 71 steps...\n",
      "INFO:root:Performing API calls on wikitext_groupings over 1 steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 results\n",
      "\r",
      "Step 0\r",
      "Step 1\r",
      "Step 2\r",
      "Step 3\r",
      "Step 4\r",
      "Step 5\r",
      "Step 6\r",
      "Step 7\r",
      "Step 8\r",
      "Step 9\r",
      "Step 10\r",
      "Step 11\r",
      "Step 12\r",
      "Step 13\r",
      "Step 14\r",
      "Step 15\r",
      "Step 16\r",
      "Step 17\r",
      "Step 18\r",
      "Step 19\r",
      "Step 20\r",
      "Step 21\r",
      "Step 22\r",
      "Step 23\r",
      "Step 24\r",
      "Step 25\r",
      "Step 26\r",
      "Step 27\r",
      "Step 28\r",
      "Step 29\r",
      "Step 30\r",
      "Step 31\r",
      "Step 32\r",
      "Step 33\r",
      "Step 34\r",
      "Step 35\r",
      "Step 36\r",
      "Step 37\r",
      "Step 38\r",
      "Step 39\r",
      "Step 40\r",
      "Step 41\r",
      "Step 42\r",
      "Step 43\r",
      "Step 44\r",
      "Step 45\r",
      "Step 46\r",
      "Step 47\r",
      "Step 48\r",
      "Step 49\r",
      "Step 50\r",
      "Step 51\r",
      "Step 52\r",
      "Step 53\r",
      "Step 54\r",
      "Step 55\r",
      "Step 56\r",
      "Step 57\r",
      "Step 58\r",
      "Step 59\r",
      "Step 60\r",
      "Step 61\r",
      "Step 62\r",
      "Step 63\r",
      "Step 64\r",
      "Step 65\r",
      "Step 66\r",
      "Step 67\r",
      "Step 68\r",
      "Step 69\r",
      "Step 70\r",
      "Step 0/1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Replacing wikitext in the sentences...\n",
      "DEBUG:root:Generating list of used wikitexts...\n",
      "DEBUG:root:There are 3163 to gather...\n",
      "INFO:root:Generating groups of wikitexts for api calls over 32 steps...\n",
      "INFO:root:Performing API calls on wikitext_groupings over 1 steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043 results\n",
      "\r",
      "Step 0\r",
      "Step 1\r",
      "Step 2\r",
      "Step 3\r",
      "Step 4\r",
      "Step 5\r",
      "Step 6\r",
      "Step 7\r",
      "Step 8\r",
      "Step 9\r",
      "Step 10\r",
      "Step 11\r",
      "Step 12\r",
      "Step 13\r",
      "Step 14\r",
      "Step 15\r",
      "Step 16\r",
      "Step 17\r",
      "Step 18\r",
      "Step 19\r",
      "Step 20\r",
      "Step 21\r",
      "Step 22\r",
      "Step 23\r",
      "Step 24\r",
      "Step 25\r",
      "Step 26\r",
      "Step 27\r",
      "Step 28\r",
      "Step 29\r",
      "Step 30\r",
      "Step 31\r",
      "Step 0/1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Replacing wikitext in the sentences...\n",
      "INFO:root:Done converting wikitext into text...\n",
      "DEBUG:root:Generating 2_id dicts for connection making...\n",
      "INFO:root:Removing empty items...\n",
      "INFO:root:Inserting data into mysql...\n",
      "DEBUG:root:Inserting entry_etymologies into mysql...\n",
      "DEBUG:root:dict_insert 2469 values: [[0, 'Borrowed from {{bor|en|ML.|dictionarium}}, f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3163 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Inserting entry_connections into mysql...\n",
      "DEBUG:root:dict_insert 4008 values: [[0, 0, 1], [1, 1, 1]]\n",
      "DEBUG:root:Inserting entry_pos into mysql...\n",
      "DEBUG:root:dict_insert 4011 values: [[0, 0, 'noun'], [0, 1, 'verb']]\n",
      "DEBUG:root:Inserting entry_definitions into mysql...\n",
      "DEBUG:root:dict_insert 6990 values: [[0, \"A reference work with a list of words from o\n",
      "DEBUG:root:Inserting entry_pronunciations into mysql...\n",
      "DEBUG:root:dict_insert 2002 values: [[0, '(Received Pronunciation) IPA(key)/ˈdɪkʃ(ə)n(\n",
      "INFO:root:Gathering wikitext parts for 2469 entries...\n",
      "DEBUG:root:Gathered 4524 connections...\n",
      "INFO:root:Converting connections into nodes...\n",
      "INFO:root:Found 5715 unmatched words. Inserting...\n",
      "DEBUG:root:number of batches: 1\n",
      "DEBUG:root:in insert(), updating sql, iteration: 0\n",
      "/Users/nish/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py:170: Warning: (1364, \"Field 'common_descendant' doesn't have a default value\")\n",
      "  result = self._query(query)\n",
      "INFO:root:Found 4203 connection_sources. Inserting...\n",
      "DEBUG:root:number of batches: 1\n",
      "DEBUG:root:in insert(), updating sql, iteration: 0\n",
      "INFO:root:Found 3622 connection_sources. Inserting...\n",
      "DEBUG:root:number of batches: 1\n",
      "DEBUG:root:in insert(), updating sql, iteration: 0\n"
     ]
    }
   ],
   "source": [
    "wp.process_wikidump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T23:27:21.736716Z",
     "start_time": "2020-08-11T23:27:21.571388Z"
    }
   },
   "outputs": [],
   "source": [
    "# parseTemplates('{{rel-top|cognates}}')\n",
    "# html = expandTemplate('{{rel-top|cognates}}'); html\n",
    "# text = getHtmlText(html); text\n",
    "# ??parseTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T02:22:23.763503Z",
     "start_time": "2020-08-12T02:22:18.031912Z"
    }
   },
   "outputs": [],
   "source": [
    "word = 'Amairgin mac Echit'\n",
    "processed_wikidump = {}\n",
    "# wp.load_wl_2_id_values()\n",
    "# wp.load_language_dict()\n",
    "# text = get_wikidump_text(word, filename='/Users/nish/development/git/wikiextractor/input/test.xml'); text\n",
    "text = get_wikidump_text(word); text\n",
    "# e = Extractor(0, 0, word, text); e\n",
    "# text = e.transform(text); text\n",
    "# text = e.wiki2text(text); text\n",
    "# text = e.clean(text); text\n",
    "# data = compact(text, e.title, e.reconstructed_language); data\n",
    "# processed_wikidump[word] = data; processed_wikidump\n",
    "# wp.get_processed_wikidump_from_single_word(word)\n",
    "# wp.get_processed_text_from_single_word(word)\n",
    "# ??wp.get_processed_wikidump_from_single_word\n",
    "# print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T04:58:37.773199Z",
     "start_time": "2020-08-12T04:58:37.483618Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "(0, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-110ad4509500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# test_cursor.d('SELECT * FROM entry_etymologies WHERE etymology LIKE \"%|%\"')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# test_cursor.d('SELECT COUNT(*) FROM entry_definitions')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdev_cursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM entry_definitions WHERE definition LIKE \"%{%\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# test_cursor.d('SELECT * FROM entry_etymologies WHERE etymology LIKE \"%|%\"')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# test_cursor.d('SELECT COUNT(*) FROM entry_definitions')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/git/dgn_utils_module/dgnutils/__init__.py\u001b[0m in \u001b[0;36md\u001b[0;34m(self, sql_stmt, values, many)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mexecute_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmany\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;31m# Choose executemany or execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_stmt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_stmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msql_stmt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'DELETE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INSERT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UPDATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpymysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, command, sql)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(0, '')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# If the last query was unbuffered, make sure it finishes before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: (0, '')"
     ]
    }
   ],
   "source": [
    "# Fix all \n",
    "#  {'pos_id': 1971, 'definition': '(punctuations) brace, curly bracket ({ })'},\n",
    "#  {'pos_id': 2169, 'definition': '{|class=\"wikitable\"'},\n",
    "#  {'pos_id': 2590, 'definition': '{|class=\"wikitable\"'},\n",
    "#  {'pos_id': 3436, 'definition': '{{examples|sense=mishearing|'},\n",
    "#  {'pos_id': 4000, 'definition': '{{examples|'}]\n",
    "# Other similar issues?\n",
    "\n",
    "# test_cursor.d('SELECT * FROM entry_definitions WHERE definition LIKE \"%{%\"')\n",
    "# test_cursor.d('SELECT * FROM entry_etymologies WHERE etymology LIKE \"%|%\"')\n",
    "# test_cursor.d('SELECT COUNT(*) FROM entry_definitions')\n",
    "dev_cursor.d('SELECT * FROM entry_definitions WHERE definition LIKE \"%{%\"')\n",
    "# test_cursor.d('SELECT * FROM entry_etymologies WHERE etymology LIKE \"%|%\"')\n",
    "# test_cursor.d('SELECT COUNT(*) FROM entry_definitions')\n",
    "# _id = 546\n",
    "# _id = get_id_from_pos_id(test_conn, 2169)\n",
    "# _id = get_id_word_and_language(test_conn, 'head')\n",
    "# get_details(test_conn, _id)\n",
    "\n",
    "# This is done after I rerun the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T02:24:41.295282Z",
     "start_time": "2020-08-12T02:24:41.265719Z"
    }
   },
   "outputs": [],
   "source": [
    "bracesIndices = set(r for f in findMatchingBraces(text) for r in range(f[0],f[1])) # All the top-level templates\n",
    "newLineIndices = [l.span()[0] for l in re.finditer(r'\\n', text) if l.span()[0] not in bracesIndices]; newLineIndices # indices of new lines\n",
    "parts = [text[i+1:j] for i,j in zip([-1] + newLineIndices, newLineIndices + [None])]; parts # Added [-1] to ensure beginning is captured\n",
    "if len(newLineIndices) > 0:\n",
    "    parts.insert(0, text[0:newLineIndices[0] ]); # Needed to get the first item in the page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T19:09:12.344523Z",
     "start_time": "2020-08-11T19:09:12.297071Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_cursor.d('SELECT * FROM entry_connections')[-1]\n",
    "test_cursor.d('SELECT * FROM etymologies WHERE _id=3598')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:57:43.466968Z",
     "start_time": "2020-08-11T18:57:42.952333Z"
    }
   },
   "outputs": [],
   "source": [
    "# 20s\n",
    "wp.load_wl_2_id_values()\n",
    "wp.load_language_dict()\n",
    "en_prons_dl, en_etys_dl, en_defs_dl = wp.get_processed_text_from_single_word('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T21:58:53.950409Z",
     "start_time": "2020-08-11T21:58:53.926524Z"
    }
   },
   "outputs": [],
   "source": [
    "# for line in re.split(r'\\n(?![^{]*})', text):\n",
    "#     print('line', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T21:59:29.108237Z",
     "start_time": "2020-08-11T21:59:28.787318Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_processed_wikidump_from_single_word(self, word):\n",
    "log_level('w')\n",
    "# options.acceptedNamespaces = ['w', 'wiktionary', 'wikt', 'reconstruction', 'wikipedia', 'wikispecies', 'rhymes', 'q', 'citations', 'wikisource', 'appendix']\n",
    "# options.keepLinks = False\n",
    "# options.expand_templates = False # templates are handled later\n",
    "\n",
    "word='word'\n",
    "processed_wikidump = {}\n",
    "text = get_wikidump_text(word); text[500:700]\n",
    "e = Extractor(0, 0, word, text); e\n",
    "text = e.transform(text); text[500:700]\n",
    "text = e.wiki2text(text); text[500:700]; text;\n",
    "data = compact(e.clean(text), e.title, e.reconstructed_language); data\n",
    "# processed_wikidump[word] = data\n",
    "# return processed_wikidump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:22:55.182749Z",
     "start_time": "2020-08-11T22:22:55.152140Z"
    }
   },
   "outputs": [],
   "source": [
    "e.clean(text); text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:20:22.920866Z",
     "start_time": "2020-08-11T22:20:22.888325Z"
    }
   },
   "outputs": [],
   "source": [
    "c = e.clean(text)\n",
    "[c[f[0]:f[1]] for f in findMatchingBraces(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:00:51.375135Z",
     "start_time": "2020-08-11T22:00:51.050983Z"
    }
   },
   "outputs": [],
   "source": [
    "for line in re.split(r'\\n(?![^{]*})', e.clean(text)):\n",
    "    print('line', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T22:25:50.260791Z",
     "start_time": "2020-08-11T22:25:50.231058Z"
    }
   },
   "outputs": [],
   "source": [
    "# out_text = clean(text)[560:900]\n",
    "out_text = \n",
    "for m in comment.finditer(text):\n",
    "        spans.append((m.start(), m.end()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T18:38:46.811242Z",
     "start_time": "2020-08-11T18:38:46.779694Z"
    }
   },
   "outputs": [],
   "source": [
    "print(get_wiki_dump_text('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T23:30:03.902717Z",
     "start_time": "2020-08-11T23:30:02.593641Z"
    }
   },
   "outputs": [],
   "source": [
    "copy_tables(test_cursor, 'etymology_explorer_dev', 'etymology_explorer_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:19:04.575597Z",
     "start_time": "2020-08-04T14:19:04.429553Z"
    }
   },
   "outputs": [],
   "source": [
    "u = os.environ['RDS_ETY_USER']; p = os.environ['RDS_ETY_PASSWORD']; h = os.environ['RDS_ETY_HOST']\n",
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:19:27.076030Z",
     "start_time": "2020-08-04T14:19:27.028749Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_cursor.e('SELECT COUNT(*) FROM connection_sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T13:37:24.744239Z",
     "start_time": "2020-08-11T13:37:24.660787Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_cursor.d('SELECT * FROM entry_connections ec INNER JOIN etymologies e ON e._id=ec.etymology_id WHERE entry_id=659')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T13:36:01.510089Z",
     "start_time": "2020-08-11T13:35:59.167285Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = dev_cursor.d('SELECT * FROM entry_etymologies LIMIT 10000'); temp\n",
    "[s for s in temp if '{' in s['etymology'] or '}' in s['etymology']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 6. Create Sentiment Analysis Model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T15:54:01.771339Z",
     "start_time": "2020-09-23T15:54:01.717121Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('d')\n",
    "wp = WikiProcessor(\n",
    "    '/Users/nish/development/git/wikiextractor/', \n",
    "    channel='dev', \n",
    "    store_intermediates=True,\n",
    ")\n",
    "# wp = WikiProcessor('/Users/nish/development/git/wikiextractor/', channel='dev', store_intermediates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T23:49:28.127618Z",
     "start_time": "2020-08-09T23:48:04.028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "notify('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-23T15:54:06.256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 60s?\n",
    "sql_stmt = \"\"\"SELECT * FROM entry_connections\"\"\"\n",
    "enid_2_etid = {d['entry_id']:d['etymology_id'] for d in dev_cursor.d(sql_stmt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-23T15:54:30.014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 120s\n",
    "sql_stmt = \"\"\"\n",
    "SELECT _id, word, language_name, ee.entry_id, wikitext \n",
    "FROM entry_etymologies ee\n",
    "INNER JOIN entry_connections ec ON ee.entry_id = ec.entry_id\n",
    "INNER JOIN etymologies e ON e._id = ec.etymology_id\n",
    "\"\"\"\n",
    "wikitext_data = dev_cursor.d(sql_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:07:10.463353Z",
     "start_time": "2020-08-08T20:07:10.437401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Troubleshooting get_sentiment_type\n",
    "from_str(', of uncertain origin -- possibly related to')\n",
    "get_sentiment_type(', of uncertain origin -- possibly related to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T00:48:05.773524Z",
     "start_time": "2020-08-10T00:48:05.699274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment_type(text, return_id=False):\n",
    "    sentiment = 'other'\n",
    "    if cognate_str(text): sentiment = 'cognate'\n",
    "    elif text in BRANCH_TEXTS: sentiment = 'branch'\n",
    "    elif text in EQUIVALENT_TEXTS: sentiment = 'equivalent'\n",
    "    elif text in RESTART_TEXTS: sentiment = 'restart'\n",
    "    elif from_str(text): sentiment = 'from'\n",
    "    \n",
    "    if return_id:\n",
    "        sentiment = stype_to_sid[sentiment]\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T00:49:43.226293Z",
     "start_time": "2020-08-10T00:48:07.556438Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 80s\n",
    "# wikitext_data[0]\n",
    "# [s for s in set((wi['entry_id'], g['preceding_text']) for wi in wikitext_data[:10000] for g in get_wikitext_parts_dict(wi).values()) if '(' in s[1]]\n",
    "# texts = set(g['preceding_text'] for wi in wikitext_data for g in get_wikitext_parts_dict(wi).values())\n",
    "sentiment_data = {\n",
    "    g['preceding_text']:{\n",
    "        'entry_id': wi['entry_id'], \n",
    "        'sentiment_type':get_sentiment_type(g['preceding_text']) \n",
    "    } for wi in wikitext_data for g in get_wikitext_parts_dict(wi).values()\n",
    "    if g['preceding_text']\n",
    "}; len(sentiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T00:50:21.397611Z",
     "start_time": "2020-08-10T00:50:21.352091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train_cursor.e('DESCRIBE interwikitext_sentiment')\n",
    "# train_cursor.e('DROP TABLE interwikitext_sentiment')\n",
    "# train_cursor.e('CREATE TABLE `interwikitext_sentiment` (\\n  `interwikitext` text COLLATE utf8mb4_bin NOT NULL,\\n  `etymology_id` int(11) NOT NULL,\\n  `sentiment` varchar(20) NOT NULL\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin')\n",
    "train_cursor.e('SELECT COUNT(*) FROM interwikitext_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T00:50:34.031717Z",
     "start_time": "2020-08-10T00:50:33.546215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment_dict_list = [\n",
    "    {\n",
    "        'interwikitext':k, \n",
    "        'etymology_id':enid_2_etid[v['entry_id']], \n",
    "        'sentiment':v['sentiment_type']\n",
    "    }\n",
    "    for k,v \n",
    "    in sentiment_data.items()\n",
    "]; len(sentiment_dict_list), sentiment_dict_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T00:50:42.805918Z",
     "start_time": "2020-08-10T00:50:38.650914Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train_cursor.e('DESCRIBE interwikitext_sentiment')\n",
    "# train_cursor.e('SELECT * FROM interwikitext_sentiment')\n",
    "train_cursor.dict_insert(sentiment_dict_list, 'interwikitext_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:19:32.788473Z",
     "start_time": "2020-08-08T20:19:31.846012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = '. This theory would be supported by a reading '\n",
    "t= ' as a corruption of \"\"'\n",
    "t = ', + noun of action suffix '\n",
    "[w for w in wikitext_data if t in w['wikitext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:19:50.094504Z",
     "start_time": "2020-08-08T20:19:49.885858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entry_id = 11276\n",
    "sql_stmt = f\"\"\"\n",
    "SELECT e.word, e.language_name \n",
    "FROM etymologies e \n",
    "INNER JOIN entry_connections ec ON e._id = ec.etymology_id\n",
    "WHERE ec.entry_id={entry_id}\"\"\"\n",
    "dev_cursor.d(sql_stmt)\n",
    "\n",
    "dev_cursor.d(f'SELECT * FROM entry_etymologies WHERE entry_id={entry_id}')[0]['wikitext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:20:55.624242Z",
     "start_time": "2020-08-08T20:20:55.599862Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_sentiment_type(' : Forms of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:11:23.093013Z",
     "start_time": "2020-08-05T19:11:21.322484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# texts_list = list(texts)\n",
    "\n",
    "sentiments = [[t,get_sentiment_type(t)] for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:11:43.206181Z",
     "start_time": "2020-08-05T19:11:43.169714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter([s[1] for s in sentiments]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Bad items\n",
    "' : According to Beekes, of '\n",
    "' : From the same source as '\n",
    "' : of '\n",
    "' : First recorded as a given name of Latvians in the end of the 19th century. From ' # period ok?\n",
    "' : Modified from above. Compare '\n",
    "' : According to Beekes, from the same '\n",
    "' : Forms of '\n",
    "' : From a poem by '\n",
    "' : From the book \"'\n",
    "' : Possibly of '\n",
    "' : Equivalent of '\n",
    "' : The kanji spelling is an example of '\n",
    "' : From Magadhi Prakrit, from Old-Indo-Aryan, akin to '\n",
    "' : From the \"műv-\" stem of '\n",
    "' : Usually considered a word of ' (8)\n",
    "' : Related to or derived from '\n",
    "' : One of the variant spellings of Nichols, from Nichol, a '\n",
    "' : From the name of the local tribe, the '\n",
    "' : From \"*teda\", from \"*tendan\", from '\n",
    "' : Taboo of mentioning '\n",
    "' : From its use in \"'\n",
    "' : Use of '\n",
    "' : From Yueyang Lou Ji by '\n",
    "' : Derived from the name \"'\n",
    "' : From \"-er-\" + '\n",
    "' : From From '\n",
    "' : From class 8 '\n",
    "' : From unknown '\n",
    "Stopped at 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:18:37.099696Z",
     "start_time": "2020-08-05T19:18:37.057191Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = ', ultimately from the same source as '\n",
    "get_sentiment_type(t), t in texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:11:27.178270Z",
     "start_time": "2020-08-05T19:11:27.151798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiments[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:29:44.663829Z",
     "start_time": "2020-08-05T19:29:44.410598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u = os.environ['RDS_ETY_USER']; p = os.environ['RDS_ETY_PASSWORD']; h = os.environ['RDS_ETY_HOST']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:38:01.902986Z",
     "start_time": "2020-08-05T19:38:01.768024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sql_create_table_1 = \"\"\"CREATE TABLE `interwikitext_sentiment` (`interwikitext` text COLLATE utf8mb4_bin NOT NULL, `etymology_id` int(11) NOT NULL, `sentiment_id` tinyint(1) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\"\"\"\n",
    "# sql_create_table_2 = \"\"\"CREATE TABLE `sentiment_types` (`sentiment_id` tinyint(1) NOT NULL, `sentiment_name` text collate utf8mb4_bin NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin\"\"\"\n",
    "# train_cursor.e('DROP TABLE interwikitext_sentiment')\n",
    "# train_cursor.e(sql_create_table_1)\n",
    "# train_cursor.e(sql_create_table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:34:42.546723Z",
     "start_time": "2020-08-05T19:34:42.467040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_cursor.e('DESCRIBE sentiment_types')\n",
    "train_cursor.e('SELECT * FROM sentiment_types')\n",
    "# sentiments = [\n",
    "#     [0, 'from'],\n",
    "#     [1, 'cognate'],\n",
    "#     [2, 'branch'],\n",
    "#     [3, 'restart'],\n",
    "#     [4, 'equivalent'],\n",
    "#     [5, 'other'],\n",
    "# ]\n",
    "# train_cursor.e('INSERT INTO sentiment_types (sentiment_id, sentiment_name) VALUES (%s, %s)', values=sentiments, many=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:21:34.151267Z",
     "start_time": "2020-08-08T20:21:34.060113Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all the wikitexts DONE\n",
    "# Get all the intermediate texts in the wikitext DONE\n",
    "# What do I want to determine? DONE\n",
    "    # Cognate, From, Reset-From, Branch\n",
    "# Figure out what the inputs and outputs are DONE\n",
    "    # text => type\n",
    "# Figure out what they would be classified as now DONE\n",
    "# Make that into a dataset (columns?) \n",
    "    # interwikitext_sentiment\n",
    "# Train it\n",
    "# Look at the most confused examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Updating sentiment based on model feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T22:32:39.407699Z",
     "start_time": "2020-08-08T22:32:37.766375Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment_dict = {t['interwikitext']:t for t in train_cursor.d('SELECT * FROM interwikitext_sentiment')}; list(sentiment_dict)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T22:30:21.181021Z",
     "start_time": "2020-08-08T22:30:21.116236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??get_sentiment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T22:47:59.800921Z",
     "start_time": "2020-08-08T22:47:59.774229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = \",accusative of \"\n",
    "# text = \"ed spelling of \"\n",
    "from_str(text)\n",
    "# get_sentiment_type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T22:48:08.932669Z",
     "start_time": "2020-08-08T22:48:08.907156Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RE_FROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T23:07:47.340780Z",
     "start_time": "2020-08-08T23:07:47.208821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_cursor.e('SELECT * FROM entry_etymologies WHERE entry_id=4544612')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T23:10:59.929781Z",
     "start_time": "2020-08-08T23:10:59.704096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('d')\n",
    "wp = WikiProcessor(\n",
    "    '/Users/nish/development/git/wikiextractor/', \n",
    "    channel='dev', \n",
    "    store_intermediates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:05:18.445792Z",
     "start_time": "2020-08-09T15:05:18.264806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wikitext = 'From an unattested onomatopoeic {{etyl|hu|onomatopoeias}} stem {{af|hu|-kel|pos1=frequentative suffix|pos=verb}}. Other words with the same stem: {{l|hu|pöfög}}, {{l|hu|pöfeteg}}.'\n",
    "# wikitext = 'From an {{af|hu|-kel|pos1=frequentative suffix|pos=verb}}. Other words with the same stem: {{l|hu|pöfög}}, {{l|hu|pöfeteg}}.'\n",
    "wp.get_connections_from_single_wikitext(wikitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:05:18.448951Z",
     "start_time": "2020-08-09T15:05:18.440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def connections_from_wikitext(wikitext):\n",
    "wp.load_language_dict()\n",
    "wtp = wp.get_wikitext_part_array([{'wikitext': wikitext, 'language_name': 'test_language', 'word': 'test_word'}])\n",
    "conns, _ = wp.get_connections_from_wikitext_parts(wtp); conns\n",
    "node_conns = wp.get_nodes_from_connections(conns); node_conns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T13:25:41.288714Z",
     "start_time": "2020-08-09T13:25:41.180672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to getWikitextsFromString -> Moved this to downstreamTasks.py\n",
    "# template = 'asdf {{bababa|asdf}} asdf {{asdf|asdf}} asdf'\n",
    "# def getWikitextsFromString(template_text:str)->list:\n",
    "#     \"\"\"Receive a string with wikitext and return the templates\"\"\"\n",
    "#     return [template_text[s_i[0]:s_i[1]] for s_i in findMatchingBraces(template_text)]\n",
    "getWikitextsFromString(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:25:54.137772Z",
     "start_time": "2020-08-09T17:25:07.893028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# See all wikitemplates to see if there are more to ignore (loading wikitexts is 40s)\n",
    "wikitext_dict = {d['entry_id']:d for d in dev_cursor.d('SELECT * from entry_etymologies')}; wikitext_dict;\n",
    "# all_templates = Counter(splitParts(w[2:-2])[0] for d in wikitext_data for w in getWikitextsFromString(d[1])); all_templates\n",
    "# templates_to_ignore = [];\n",
    "# all_templates.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:26:16.293647Z",
     "start_time": "2020-08-09T17:25:54.140115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find largest examples of wikitexts (20s)\n",
    "# all_templates.most_common()[:5]\n",
    "# Get a set of template type and an example of the template (the longest one)\n",
    "template_examples = {}\n",
    "for value in list(wikitext_dict.values()):\n",
    "    for template in getWikitextsFromString(value['wikitext']):\n",
    "        template_type = splitParts(template[2:-2])[0]\n",
    "        if len(template_examples.setdefault(template_type, {}).setdefault('shortest', template)) > len(template):\n",
    "            template_examples[template_type]['shortest'] = template\n",
    "        if len(template_examples[template_type].setdefault('longest', template)) < len(template):\n",
    "            template_examples[template_type]['longest'] = template\n",
    "# template_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:26:23.686138Z",
     "start_time": "2020-08-09T17:26:23.489990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parseTemplates('{{wikidata|Q577034|Laconic phrases}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:55:53.852461Z",
     "start_time": "2020-08-09T17:55:53.408238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find wikitext info for some text (set wt)\n",
    "# wt = '{{wikidata|Q577034|Laconic phrases}}'\n",
    "for k,v in wikitext_dict.items():\n",
    "    if wt in v['wikitext']:\n",
    "        entry_id = k\n",
    "        etymology_id = dev_cursor.e(f'SELECT etymology_id FROM entry_connections WHERE entry_id={entry_id}')[0][0]\n",
    "        print(get_details(dev_conn, etymology_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:12:05.971977Z",
     "start_time": "2020-08-09T17:12:05.945293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# soup.find_all('div', {'style'})\n",
    "# div = soup.find_all(\"div\", {'class':'noprint'})[0]; div\n",
    "# div.decompose()\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:56:48.684179Z",
     "start_time": "2020-08-09T17:56:48.579375Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "template_type = list(template_examples)[484]; template_type\n",
    "wt = template_examples[template_type]['longest']; wt\n",
    "wt = template_examples[template_type]['shortest']; wt\n",
    "# wt = '{{wikisource1911Enc|Aard-wolf}}'\n",
    "# wt = '{{bor|la|en|Aard-wolf}}'\n",
    "html = expandTemplate(wt, session, True); html\n",
    "soup = bs4.BeautifulSoup(html, features='lxml'); soup\n",
    "# for div in soup.find_all(\"table\", {'class':'metadata'}): \n",
    "#     print(div)\n",
    "#     div.decompose()\n",
    "# print(soup.get_text())\n",
    "# text = getHtmlText(html); text\n",
    "# linklessText = replaceInternalLinks(text); linklessText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:09:35.971886Z",
     "start_time": "2020-08-09T15:06:28.910896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find wikitexts that dont expand into anything\n",
    "for i, template_type in enumerate(list(template_examples)):\n",
    "    print(f'\\r{i}/{len(template_examples)}', end='')\n",
    "    template_examples[template_type]['shortest_text'] = parseTemplates(template_examples[template_type]['shortest'], session=session, cache=True)\n",
    "    template_examples[template_type]['longest_text'] = parseTemplates(template_examples[template_type]['longest'], session=session, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "180/677\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Standard Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Standard Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Standard Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Standard Chinese\"\n",
    "293/677\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[Appendix\" of \"[Appendix:Glossary#sic\"\n",
    "302/677\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Man'yōgana\"\n",
    "452/677\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Classical Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Classical Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Classical Chinese\"\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[w\" of \"[w:Classical Chinese\"\n",
    "483/677\n",
    "WARNING:root:unaccepted options.acceptedNamespaces: \"[Appendix\" of \"[Appendix:Glossary#sic\"\n",
    "\n",
    "676/677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:36:59.133096Z",
     "start_time": "2020-08-09T14:36:59.103609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the list of templates that don't expand and those that sometimes expand\n",
    "no_expand_templates = []\n",
    "sometimes_expand_templates = []\n",
    "never_expand_templates = []\n",
    "for template_type in list(template_examples):\n",
    "    se = bool(template_examples[template_type]['shortest_text'])\n",
    "    le = bool(template_examples[template_type]['longest_text'])\n",
    "    if not se and not le: \n",
    "        no_expand_templates.append(template_type)\n",
    "    elif not se or not le: \n",
    "        sometimes_expand_templates.append(template_type)\n",
    "    else:\n",
    "        never_expand_templates.append(template_type)\n",
    "print([len(l) for l in [no_expand_templates, sometimes_expand_templates, never_expand_templates]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:37:43.967392Z",
     "start_time": "2020-08-09T14:37:43.942338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extra no expand templates:\n",
    "# wikisource1911Enc\n",
    "# projectlink\n",
    "# PL:1911\n",
    "# wikiquote\n",
    "no_expand_templates\n",
    "template_examples['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:38:40.053777Z",
     "start_time": "2020-08-09T14:38:38.967479Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:52:03.680276Z",
     "start_time": "2020-08-09T14:52:03.625618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(tailRE)\n",
    "replaceInternalLinks2(out)\n",
    "makeInternalLink('wikipedia:ru:Шпалерная тюрьма', '\"Шпалерная тюрьма\", a prison in Saint Petersburg, named according to the street where it is located')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:44:27.233482Z",
     "start_time": "2020-08-09T14:44:27.118019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = expandTemplate('{{w|lang=ru|Шпалерная тюрьма|\"Шпалерная тюрьма\", a prison in Saint Petersburg, named according to the street where it is located}}', session, True); out\n",
    "# list(findMatchingBraces(out))\n",
    "print(out)\n",
    "replaceInternalLinks('[[out]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T14:39:22.137045Z",
     "start_time": "2020-08-09T14:39:22.053760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_cursor.d('SELECT * FROM entry_connections WHERE entry_id=4610941')\n",
    "get_details(dev_conn, 2071949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T13:36:26.528862Z",
     "start_time": "2020-08-09T13:36:26.496877Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wikitext_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T13:28:28.206210Z",
     "start_time": "2020-08-09T13:28:28.181538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'catlangname' in all_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T18:04:14.928801Z",
     "start_time": "2020-08-09T18:04:14.901173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T18:50:12.029964Z",
     "start_time": "2020-08-09T18:50:12.003587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A new way to expand templates using WikiExtractor.py\n",
    "from WikiExtractor import Extractor, load_templates, fileinput\n",
    "wt = 'banana {{w|lang=ru|Шпалерная тюрьма|\"Шпалерная тюрьма\", a prison in Saint Petersburg, named according to the street where it is located}} test'\n",
    "e = Extractor(0, 0, 'temp', wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T18:06:57.838246Z",
     "start_time": "2020-08-09T18:06:57.813774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e.expandTemplate('w|test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T18:10:16.510810Z",
     "start_time": "2020-08-09T18:10:16.484125Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_level('d')\n",
    "# e.transform(e.text)\n",
    "e.expand(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T18:49:19.632009Z",
     "start_time": "2020-08-09T18:49:19.477870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %pwd\n",
    "# '/Users/nish/development/git/wikiextractor/templates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T20:30:22.998728Z",
     "start_time": "2020-08-09T20:30:22.950376Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "options.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T20:32:42.615175Z",
     "start_time": "2020-08-09T20:32:42.519406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 20s\n",
    "# file = fileinput.FileInput('/Users/nish/development/git/wikiextractor/templates', openhook=fileinput.hook_compressed)\n",
    "# load_templates(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Making exclude_connection_forming option for multi_parse_wikitext_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T20:37:33.251764Z",
     "start_time": "2020-08-09T20:37:33.204012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# wikitext_list = set(s[s_i[0]:s_i[1]] for s in sentences for s_i in findMatchingBraces(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T20:45:24.653782Z",
     "start_time": "2020-08-09T20:45:24.582414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences = [d[0] for d in dev_cursor.e('SELECT wikitext FROM entry_etymologies LIMIT 100')]; sentences\n",
    "wikitext_list = set(s[s_i[0]:s_i[1]] for s in sentences for s_i in findMatchingBraces(s)); wikitext_list\n",
    "wikitext_list.add('{{etyl|test|test}}')\n",
    "[[w, wikitext_is_connection_forming(w)] for w in wikitext_list if not wikitext_is_connection_forming(w)]\n",
    "# wikitext_list = [w for w in wikitext_list if wikitext_is_connection_forming(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T20:47:06.785685Z",
     "start_time": "2020-08-09T20:47:06.296297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wt = '{{noncog|fro|livret|t=book, booklet}}'\n",
    "# wt = '{{wikidata|Q577034|Laconic phrases}}'\n",
    "for k,v in wikitext_dict.items():\n",
    "    if wt in v['wikitext']:\n",
    "        entry_id = k\n",
    "        etymology_id = dev_cursor.e(f'SELECT etymology_id FROM entry_connections WHERE entry_id={entry_id}')[0][0]\n",
    "        print(get_details(dev_conn, etymology_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get a list of sentences along with the type of connection it made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get all the preceeding texts before wikitexts\n",
    "# Really I'd like it to get the full thing and then just extract {{test}} is from {{test2}}, entry_id\n",
    "# To get that data, I'll take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-30T17:46:30.535Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev_conn, dev_cursor = connect('etymology_explorer_dev', user=u, password=p, host=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T16:09:41.816591Z",
     "start_time": "2020-07-30T16:07:00.603551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Temp get all word-> ids\n",
    "# temp = dev_cursor.d('SELECT * FROM etymologies word'); temp\n",
    "temp.sort(key=lambda x:x['word'].lower() if x['word'][:1].lower() in 'abcdefghijklmnopqrstuvwxyz' else '~'+x['word'].lower()); temp[:4]\n",
    "temp_dict = {}\n",
    "for t in temp:\n",
    "    temp_dict.setdefault(t['language_name'], {})[t['word']] = t['_id']\n",
    "\n",
    "list(temp_dict['English'].keys())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T17:05:10.154331Z",
     "start_time": "2020-07-30T17:05:09.492892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sum(len(v) for v in temp_dict.values())\n",
    "len(set([t.replace('\\u200e', '').strip() for t in temp_dict['English'] if ' ' not in t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T17:17:00.696627Z",
     "start_time": "2020-07-30T17:16:50.869541Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/nish/development/projects/etymology-explorer-web/src/utils/word_dict.json', 'w') as f:\n",
    "    f.write(json.dumps({'English':temp_dict['English']},separators=(',', ':')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikiextractor",
   "language": "python",
   "name": "wikiextractor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
